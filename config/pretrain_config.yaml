# ===================================================================
# COCONUT STAGE 1: PRETRAIN CONFIGURATION
#
# ğŸ¯ DESIGN PHILOSOPHY:
#   - Goal: Build robust and well-separated feature space
#   - Strategy: Hybrid Loss (ArcFace + SupCon) without W2ML
#   - Rationale: Prevent overfitting to specific dataset characteristics
#
# ğŸš« WHY NOT W2ML in PRETRAIN:
#   1. W2ML focuses on hard samples â†’ risk of learning dataset noise
#   2. Generalization is priority â†’ stable learning preferred
#   3. Foundation must be robust â†’ avoid premature specialization
#
# âœ… WHY HYBRID LOSS:
#   1. ArcFace: Creates large inter-class margins
#   2. SupCon: Enhances intra-class cohesion  
#   3. Combination: Proven effective in CCNet paper
# ===================================================================

Dataset:
  type: Tongji_Pretrain
  train_set_file: './data/train_tongji.txt'
  test_set_file: './data/test_tongji.txt'
  height: 128
  width: 128
  use_angle_normalization: False

PalmRecognizer:
  architecture: CCNet
  num_classes: 600
  com_weight: 0.8
  learning_rate: 0.001
  batch_size: 1024
  feature_dimension: 2048

Training:
  batch_size: 1024
  epoch_num: 3000
  lr: 0.001
  redstep: 500
  gpu_id: 0

# ğŸ”¥ í•˜ì´ë¸Œë¦¬ë“œ ì†ì‹¤ í•¨ìˆ˜ ì„¤ì • (CCNet ê²€ì¦ëœ ë¹„ìœ¨)
Loss:
  temp: 0.07
  weight1: 0.8  # ArcFace ê°€ì¤‘ì¹˜ (ë¶„ë¥˜ + ë§ˆì§„)
  weight2: 0.2  # SupCon ê°€ì¤‘ì¹˜ (íŠ¹ì§• êµ¬ì¡°í™”)

Paths:
  checkpoint_path: './results/pretrained_models/'
  results_path: './results/pretrain_eval/'
  save_interval: 500
  test_interval: 1000

Design_Documentation:
  stage1_philosophy: "Stable hybrid learning for robust generalization"
  loss_strategy: "ArcFace (0.8) + SupCon (0.2) hybrid"
  w2ml_exclusion_rationale: "Prevents overfitting to dataset-specific noise"
  mathematical_basis: "CCNet validated 0.8:0.2 ratio"
  next_stage: "W2ML-based adaptation in Stage 2"