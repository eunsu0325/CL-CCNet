# config/adapt_config.yaml - ë°°ì¹˜ ê¸°ë°˜ ì„¤ì •

# =================================================================
# DESIGN PHILOSOPHY (Batch-based Control)
# =================================================================
Design_Documentation:
  philosophy: "Batch-based Continual Learning for Palmprint Recognition"
  core_innovation: "Process samples in batches with automatic positive pairs"
  main_contribution: "Efficient GPU utilization with simplified control flow"
  loss_strategy: "SupCon with guaranteed positive pairs from batch"
  buffer_strategy: "Diversity-based storage with per-user limits"

# =================================================================
# DATASET CONFIGURATION
# =================================================================
Dataset:
  type: "palmprint"
  height: 128
  width: 128
  use_angle_normalization: false
  dataset_path: "/content/drive/MyDrive/CCNet_OKD_CD/data/train_Tongji.txt"
  
  # ðŸ”¥ BATCH PROCESSING
  samples_per_label: 5  # Process 5 samples per user at once

# =================================================================
# MODEL CONFIGURATION
# =================================================================
PalmRecognizer:
  architecture: "CCNet"
  num_classes: 600
  com_weight: 0.8
  feature_dimension: 2048
  learning_rate: 0.001
  batch_size: 1024  # For compatibility
  load_weights_folder: "/content/drive/MyDrive/net_params1.pth"
  
  # Headless Configuration
  headless_mode: true
  verification_method: "metric"
  metric_type: "cosine"
  similarity_threshold: 0.5
  compression_dim: 128

# =================================================================
# CONTINUAL LEARNER CONFIGURATION (SIMPLIFIED)
# =================================================================
ContinualLearner:
  adaptation: true
  adaptation_epochs: 1  # Per batch
  sync_frequency: 10
  replay_weight: 1.0
  new_data_weight: 1.0
  intermediate_save_frequency: 50
  learning_rate: 0.001
  
  # ðŸ”¥ BATCH CONFIGURATION
  training_batch_size: 32  # Total batch size for training
  hard_negative_ratio: 0.3  # 30% of buffer samples are hard negatives

# =================================================================
# REPLAY BUFFER CONFIGURATION (SIMPLIFIED)
# =================================================================
ReplayBuffer:
  maximize_diversity: true
  max_buffer_size: 200  # Increased for better diversity
  similarity_threshold: 0.85
  storage_path: "./results/replay_buffer/"
  feature_extraction_for_diversity: true
  enable_smart_sampling: true
  diversity_update_frequency: 10
  model_save_path: "./results/models/"
  
  # ðŸ”¥ SIMPLIFIED CONFIGURATION
  samples_per_user_limit: 3  # Maximum samples per user in buffer

# =================================================================
# LOSS CONFIGURATION
# =================================================================
Loss:
  temp: 0.07
  type: "SupConLoss"

# =================================================================
# MODEL SAVING CONFIGURATION
# =================================================================
ModelSaving:
  final_save_path: "/content/drive/MyDrive/CoCoNut_BatchMode"
  intermediate_save_frequency: 100
  enable_intermediate_save: true
  include_timestamp: true
  auto_generate_readme: true

# =================================================================
# DATA AUGMENTATION (OPTIONAL)
# =================================================================
DataAugmentation:
  enable_augmentation: false  # Disabled for consistency
  augmentation_probability: 0.4
  enable_geometric: true
  geometric_probability: 0.3
  max_rotation_degrees: 3
  max_translation_ratio: 0.05