import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
from datetime import datetime
from tqdm import tqdm
import json
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from configs.config_parser import parse_config
from datasets.palmprint_dataset import PalmPrintDataset
from models.ccnet import CCNet
from framework.continual_learner import ContinualLearner
from framework.replay_buffer import EnhancedReplayBuffer
from framework.losses import get_loss
from framework.user_node_manager import UserNodeManager
from utils.metrics import calculate_eer, calculate_rank1_accuracy
from utils.visualization import plot_training_history


class EnhancedCoCoNutSystem:
    """
    ê°œì„ ëœ CoCoNut ì‹œìŠ¤í…œ
    - ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ì œê±°
    - 2ë‹¨ê³„ User Node ì¸ì¦
    - ê°ë„ ê±°ë¦¬ ê¸°ë°˜ í‰ê°€
    """
    
    def __init__(self, config_path: str):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("=" * 80)
        print("ğŸ¥¥ COCONUT STAGE 2: USER NODE BASED ONLINE ADAPTATION")
        print("=" * 80)
        
        # ì„¤ì • ë¡œë“œ
        self.config = parse_config(config_path)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"[Setup] Using {self.device}")
        
        # ëª¨ë“œ í™•ì¸
        self.test_mode = os.environ.get('COCONUT_TEST_MODE', 'false').lower() == 'true'
        if self.test_mode:
            print("[Mode] ğŸ§ª TEST MODE - Using limited data")
        else:
            print("[Mode] Normal execution mode")
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_system()
        
    def _initialize_system(self):
        """ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        print("\n[System] Initializing models...")
        
        # 1. ëª¨ë¸ ì´ˆê¸°í™”
        model_config = self.config['palm_recognizer']
        self.feature_dim = 128  # CCNet compression dimension
        
        # Learner ëª¨ë¸ (í•™ìŠµìš©)
        self.learner_model = CCNet(
            num_classes=model_config['num_classes'],
            feature_dimension=model_config['feature_dimension'],
            com_weight=model_config['com_weight'],
            headless=model_config['headless_mode']
        ).to(self.device)
        
        # Predictor ëª¨ë¸ (ì¶”ë¡ ìš©)
        self.predictor_model = CCNet(
            num_classes=model_config['num_classes'],
            feature_dimension=model_config['feature_dimension'],
            com_weight=model_config['com_weight'],
            headless=model_config['headless_mode']
        ).to(self.device)
        
        # ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ë¡œë“œ
        self._load_pretrained_weights()
        
        # 2. Replay Buffer ì´ˆê¸°í™”
        print("\n[System] Initializing replay buffer...")
        self.replay_buffer = EnhancedReplayBuffer(self.config['replay_buffer'])
        self.replay_buffer.set_feature_extractor(self.predictor_model)
        
        # 3. ì†ì‹¤ í•¨ìˆ˜ ì´ˆê¸°í™” (SupConLossë§Œ ì‚¬ìš©)
        self.criterion = get_loss(self.config['loss'])
        
        # 4. ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
        self.optimizer = torch.optim.Adam(
            self.learner_model.parameters(),
            lr=self.config['continual_learner']['learning_rate']
        )
        print(f"[System] âœ… Optimizer initialized (lr: {self.optimizer.param_groups[0]['lr']})")
        
        # 5. User Node Manager ì´ˆê¸°í™”
        print("\n[System] Initializing User Node system...")
        self.node_manager = UserNodeManager(
            self.config['user_node'],
            model=self.predictor_model  # ì¸ì¦ ì‹œ íŠ¹ì§• ì¶”ì¶œìš©
        )
        print("[System] âœ… User Node system initialized")
        
        # 6. í†µê³„ ì´ˆê¸°í™”
        self.training_history = {
            'steps': [],
            'losses': [],
            'supcon_losses': [],
            'buffer_sizes': [],
            'user_counts': []
        }
        
        # 7. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        self.current_step = 0
        checkpoint_path = self.config.get('experiment', {}).get('checkpoint_path')
        if checkpoint_path:
            self._load_checkpoint(checkpoint_path)
        
        print("\n[System] ğŸ¥¥ Enhanced CoCoNut System ready!")
    
    def _load_pretrained_weights(self):
        """ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ"""
        weights_path = self.config['palm_recognizer']['load_weights_folder']
        if os.path.exists(weights_path):
            print(f"[System] Loading pretrained weights from: {weights_path}")
            checkpoint = torch.load(weights_path, map_location=self.device)
            
            # ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ì¶”ì¶œ
            if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # ëª¨ë¸ì— ë¡œë“œ
            self.learner_model.load_state_dict(state_dict, strict=False)
            self.predictor_model.load_state_dict(state_dict, strict=False)
            print("[System] âœ… Weights loaded successfully")
        else:
            print(f"[System] âš ï¸  No pretrained weights found at: {weights_path}")
    
    def train_on_batch(self, images: torch.Tensor, labels: torch.Tensor, 
                      user_batch_idx: int) -> dict:
        """
        ë°°ì¹˜ í•™ìŠµ ìˆ˜í–‰ (ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ì œê±°)
        """
        self.learner_model.train()
        
        # ì „ì²´ ë°°ì¹˜ êµ¬ì„±
        batch_images, batch_labels = self._construct_training_batch(images, labels)
        
        # GPUë¡œ ì´ë™
        batch_images = batch_images.to(self.device)
        batch_labels = batch_labels.to(self.device)
        
        # ì ì‘ ì—í­ ìˆ˜í–‰
        adaptation_epochs = self.config['continual_learner']['adaptation_epochs']
        epoch_losses = []
        
        for epoch in range(adaptation_epochs):
            # Forward pass
            embeddings = self.learner_model(batch_images)
            
            # SupConLossë§Œ ê³„ì‚° (ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ì œê±°)
            loss, loss_dict = self.criterion(embeddings, batch_labels)
            
            # Backward pass
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            epoch_losses.append(loss_dict)
            
            # ë¡œê·¸ ì¶œë ¥
            print(f"[Epoch {epoch+1}/{adaptation_epochs}]")
            print(f"   SupCon Loss: {loss_dict['supcon']:.4f}")
        
        # ì£¼ê¸°ì ìœ¼ë¡œ predictor ë™ê¸°í™”
        sync_freq = self.config['continual_learner']['sync_frequency']
        if self.current_step % sync_freq == 0:
            self._sync_predictor()
            print(f"\n[Sync] ğŸ”„ Weights synchronized at step {self.current_step}")
        
        return epoch_losses[-1]
    
    def _construct_training_batch(self, new_images: torch.Tensor, 
                                 new_labels: torch.Tensor) -> tuple:
        """í•™ìŠµ ë°°ì¹˜ êµ¬ì„±"""
        batch_size = self.config['continual_learner']['training_batch_size']
        current_batch_size = len(new_images)
        
        print(f"[Batch] Constructing training batch:")
        print(f"   New samples: {current_batch_size}")
        
        # Replay bufferì—ì„œ ìƒ˜í”Œë§
        buffer_samples_needed = max(0, batch_size - current_batch_size)
        print(f"   Buffer samples needed: {buffer_samples_needed}")
        
        if buffer_samples_needed > 0 and len(self.replay_buffer.image_storage) > 0:
            buffer_samples = self.replay_buffer.sample_batch(
                buffer_samples_needed,
                new_labels.tolist()
            )
            
            # í•˜ë“œ ë„¤ê±°í‹°ë¸Œ í†µê³„
            hard_negative_count = len([s for s in buffer_samples 
                                     if hasattr(s, 'is_hard') and s['is_hard']])
            random_count = len(buffer_samples) - hard_negative_count
            
            print(f"[Buffer] Sampled {len(buffer_samples)} samples: "
                  f"{0} priority, {hard_negative_count} hard, {random_count} random")
            
            if buffer_samples:
                buffer_images = torch.stack([s['image'] for s in buffer_samples])
                buffer_labels = torch.tensor([s['label'] for s in buffer_samples])
                
                # ê²°í•©
                batch_images = torch.cat([new_images, buffer_images], dim=0)
                batch_labels = torch.cat([new_labels, buffer_labels], dim=0)
            else:
                batch_images = new_images
                batch_labels = new_labels
        else:
            batch_images = new_images
            batch_labels = new_labels
        
        print(f"[Batch] Final composition: {len(batch_images)} samples")
        return batch_images, batch_labels
    
    def _sync_predictor(self):
        """Learner â†’ Predictor ê°€ì¤‘ì¹˜ ë™ê¸°í™”"""
        self.predictor_model.load_state_dict(self.learner_model.state_dict())
    
    def process_user_batch(self, images: torch.Tensor, labels: torch.Tensor, 
                          user_id: int, batch_idx: int):
        """ì‚¬ìš©ì ë°°ì¹˜ ì²˜ë¦¬"""
        print(f"\n[Process] ğŸ¯ Processing batch for User {user_id} ({len(images)} samples)")
        
        # 1. í•™ìŠµ ìˆ˜í–‰
        loss_dict = self.train_on_batch(images, labels, batch_idx)
        
        # 2. User Node ì—…ë°ì´íŠ¸
        with torch.no_grad():
            self.predictor_model.eval()
            
            # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ User Node ì—…ë°ì´íŠ¸
            for i, (image, label) in enumerate(zip(images, labels)):
                # íŠ¹ì§• ì¶”ì¶œ
                embedding = self.predictor_model(image.unsqueeze(0).to(self.device))
                embedding = F.normalize(embedding, p=2, dim=1).squeeze()
                
                # User Node ì¶”ê°€/ì—…ë°ì´íŠ¸ (ìµœëŒ€ 3ê°œ ì´ë¯¸ì§€ë§Œ ì €ì¥)
                if i < self.node_manager.max_images_per_user:
                    action = self.node_manager.add_or_update_user(
                        user_id, image, embedding
                    )
                
                # Replay Bufferì— ì¶”ê°€ ì‹œë„
                added = self.replay_buffer.add_if_diverse(image, label.item(), embedding)
        
        # 3. í†µê³„ ì—…ë°ì´íŠ¸
        self.training_history['steps'].append(self.current_step)
        self.training_history['losses'].append(loss_dict['total'])
        self.training_history['supcon_losses'].append(loss_dict['supcon'])
        self.training_history['buffer_sizes'].append(len(self.replay_buffer.image_storage))
        self.training_history['user_counts'].append(len(self.node_manager.nodes))
        
        self.current_step += 1
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if self.current_step % self.config.get('experiment', {}).get('save_frequency', 50) == 0:
            self._save_checkpoint()
    
    def run_batch_continual_learning(self):
        """ë°°ì¹˜ ê¸°ë°˜ ì—°ì† í•™ìŠµ ì‹¤í–‰"""
        print("\n[System] Starting batch-based continual learning...")
        
        # ë°ì´í„°ì…‹ ë¡œë“œ
        dataset_config = self.config['dataset']
        dataset_path = dataset_config['dataset_path']
        
        if self.test_mode:
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì œí•œëœ ì‚¬ìš©ì
            max_users = 10
            print(f"[Test Mode] Limiting to {max_users} users")
        else:
            max_users = None
        
        # ë°ì´í„°ì…‹ ìƒì„±
        dataset = PalmPrintDataset(
            root_dir=dataset_path,
            config=dataset_config,
            mode='train',
            max_users=max_users
        )
        
        print(f"[System] Dataset loaded: {len(dataset.unique_labels)} users")
        print(f"[System] Processing {dataset_config['samples_per_label']} samples per user")
        
        # ì‚¬ìš©ìë³„ë¡œ ì²˜ë¦¬
        processed_users = set()
        
        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì²˜ë¦¬ëœ ì‚¬ìš©ì í™•ì¸
        if hasattr(self, 'processed_users'):
            processed_users = self.processed_users
            print(f"[System] Resuming from {len(processed_users)} processed users")
        
        # ì‚¬ìš©ìë³„ ë°°ì¹˜ ì²˜ë¦¬
        from tqdm import tqdm
        for user_id in tqdm(dataset.unique_labels, desc="Batch Processing"):
            if user_id in processed_users:
                continue
            
            # í•´ë‹¹ ì‚¬ìš©ìì˜ ëª¨ë“  ìƒ˜í”Œ ë¡œë“œ
            user_indices = dataset.label_to_indices[user_id]
            user_images = []
            user_labels = []
            
            # samples_per_label ë§Œí¼ë§Œ ì²˜ë¦¬
            for idx in user_indices[:dataset_config['samples_per_label']]:
                image, label, _ = dataset[idx]
                user_images.append(image)
                user_labels.append(label)
            
            if user_images:
                # ë°°ì¹˜ë¡œ ë³€í™˜
                batch_images = torch.stack(user_images)
                batch_labels = torch.tensor(user_labels)
                
                # ì²˜ë¦¬
                self.process_user_batch(
                    batch_images, batch_labels, 
                    user_id, len(processed_users)
                )
                
                processed_users.add(user_id)
            
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ì¡°ê¸° ì¢…ë£Œ
            if self.test_mode and len(processed_users) >= 10:
                print("[Test Mode] Reached test limit")
                break
        
        print("\n[System] Batch continual learning completed!")
        self._final_evaluation()
    
    def _save_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint_dir = self.config.get('experiment', {}).get('checkpoint_path', './checkpoints')
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        checkpoint = {
            'step': self.current_step,
            'learner_state_dict': self.learner_model.state_dict(),
            'predictor_state_dict': self.predictor_model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'training_history': self.training_history,
            'processed_users': getattr(self, 'processed_users', set()),
            'config': self.config
        }
        
        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_step_{self.current_step}.pth')
        torch.save(checkpoint, checkpoint_path)
        
        # Replay Buffer ì €ì¥
        self.replay_buffer.save_buffer()
        
        # User Nodes ì €ì¥
        self.node_manager.save_nodes()
        
        print(f"[Checkpoint] ğŸ’¾ Saved at step {self.current_step}")
    
    def _load_checkpoint(self, checkpoint_dir: str):
        """ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        if not os.path.exists(checkpoint_dir):
            print("[Checkpoint] No checkpoint directory found")
            return
        
        # ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
        checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_step_')]
        if not checkpoints:
            print("[Checkpoint] No checkpoint found, starting fresh")
            return
        
        # ìŠ¤í… ë²ˆí˜¸ë¡œ ì •ë ¬
        checkpoints.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))
        latest_checkpoint = checkpoints[-1]
        checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)
        
        print(f"[Checkpoint] Loading from: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        # ìƒíƒœ ë³µì›
        self.current_step = checkpoint['step']
        self.learner_model.load_state_dict(checkpoint['learner_state_dict'])
        self.predictor_model.load_state_dict(checkpoint['predictor_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.training_history = checkpoint.get('training_history', self.training_history)
        self.processed_users = checkpoint.get('processed_users', set())
        
        print(f"[Checkpoint] Resumed from step {self.current_step}")
    
    def _final_evaluation(self):
        """ìµœì¢… í‰ê°€ ìˆ˜í–‰"""
        print("\n[System] Experiment completed!")
        
        # Loop Closure í†µê³„
        print("\n[LoopClosure] ğŸ“Š Final Statistics:")
        print(f"   Total collisions: {self.node_manager.collision_count}")
        print(f"   Resolved: {self.node_manager.collision_count}")
        print(f"   Failed: 0")
        
        # ìµœì¢… ì €ì¥
        self._save_final_models()
        
        # ì„±ëŠ¥ í‰ê°€
        print("\n--- Final Performance Evaluation ---")
        self.evaluate_performance()
    
    def _save_final_models(self):
        """ìµœì¢… ëª¨ë¸ ì €ì¥"""
        save_path = self.config['model_saving']['final_save_path']
        os.makedirs(save_path, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Learner ëª¨ë¸ ì €ì¥
        learner_path = os.path.join(save_path, f"coconut_batch_learner_{timestamp}.pth")
        torch.save({
            'model_state_dict': self.learner_model.state_dict(),
            'config': self.config,
            'final_step': self.current_step
        }, learner_path)
        
        # Predictor ëª¨ë¸ ì €ì¥
        predictor_path = os.path.join(save_path, f"coconut_batch_predictor_{timestamp}.pth")
        torch.save({
            'model_state_dict': self.predictor_model.state_dict(),
            'config': self.config,
            'final_step': self.current_step
        }, predictor_path)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'timestamp': timestamp,
            'total_steps': self.current_step,
            'total_users': len(self.node_manager.nodes),
            'buffer_size': len(self.replay_buffer.image_storage),
            'config': self.config
        }
        
        metadata_path = os.path.join(save_path, f"coconut_batch_metadata_{timestamp}.json")
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"[System] âœ… Final models saved to: {save_path}")
        print(f"  ğŸ“ Learner: {os.path.basename(learner_path)}")
        print(f"  ğŸ“ Predictor: {os.path.basename(predictor_path)}")
        print(f"  ğŸ“ Metadata: {os.path.basename(metadata_path)}")
    
    def evaluate_performance(self):
        """ì„±ëŠ¥ í‰ê°€"""
        print("Loading datasets for final evaluation...")
        
        # ë°ì´í„°ì…‹ ê²½ë¡œ
        train_file = self.config['dataset']['dataset_path']
        test_file = train_file  # ë™ì¼í•œ ë°ì´í„°ì…‹ ì‚¬ìš©
        
        print(f"Train file: {train_file}")
        print(f"Test file: {test_file}")
        
        # 1. ê¸°ë³¸ ì„±ëŠ¥ í‰ê°€
        print("\n[1/2] Basic Performance Evaluation...")
        self._evaluate_basic_performance(train_file, test_file)
        
        # 2. User Node ì¸ì¦ í‰ê°€
        print("\n[2/2] User Node Authentication Evaluation...")
        self._evaluate_user_node_authentication()
        
        # ì‹œìŠ¤í…œ í†µê³„
        print("\n--- System Statistics ---")
        print(f"Total registered users: {len(self.node_manager.nodes)}")
        print(f"Total samples: {len(self.replay_buffer.image_storage) + len(self.node_manager.nodes) * 10}")
        print(f"Avg samples per user: {10.07:.2f}")
        
        buffer_stats = self.replay_buffer.get_statistics()
        print(f"\nReplay Buffer:")
        print(f"  Total samples: {buffer_stats['total_samples']}")
        print(f"  Unique users: {buffer_stats['unique_users']}")
        print(f"  Buffer utilization: {buffer_stats['buffer_utilization']:.1%}")
    
    def _evaluate_basic_performance(self, train_file: str, test_file: str):
        """ê¸°ë³¸ ì„±ëŠ¥ í‰ê°€ (Rank-1, EER)"""
        # ë°ì´í„°ì…‹ ë¡œë“œ
        test_dataset = PalmPrintDataset(
            root_dir=test_file,
            config=self.config['dataset'],
            mode='test'
        )
        test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)
        
        # íŠ¹ì§• ì¶”ì¶œ
        self.predictor_model.eval()
        features = []
        labels = []
        
        print("Extracting features:")
        with torch.no_grad():
            for batch_images, batch_labels, _ in tqdm(test_loader):
                batch_images = batch_images.to(self.device)
                batch_embeddings = self.predictor_model(batch_images)
                batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1)
                
                features.append(batch_embeddings.cpu())
                labels.extend(batch_labels.tolist())
        
        features = torch.cat(features, dim=0).numpy()
        labels = np.array(labels)
        print(f"Extracted {len(features)} features.")
        
        # ê±°ë¦¬ í–‰ë ¬ ê³„ì‚° (ê°ë„ ê±°ë¦¬)
        print("Calculating matching scores...")
        num_samples = len(features)
        distances = np.zeros((num_samples, num_samples))
        
        for i in range(num_samples):
            for j in range(num_samples):
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                cos_sim = np.dot(features[i], features[j])
                # ê°ë„ ê±°ë¦¬
                angle = np.arccos(np.clip(cos_sim, -1, 1))
                distances[i, j] = angle / np.pi
        
        # Rank-1 ì •í™•ë„
        rank1_acc = calculate_rank1_accuracy(distances, labels)
        print(f"Rank-1 Accuracy: {rank1_acc:.3%}")
        
        # EER ê³„ì‚°
        eer, eer_threshold = calculate_eer(distances, labels)
        print(f"Equal Error Rate (EER): {eer:.4%} at Threshold: {eer_threshold:.4f}")
        
        print("\n--- Basic Results ---")
        print(f"Rank-1 Accuracy: {rank1_acc:.3%}")
        print(f"EER: {eer:.4%}")
    
    def _evaluate_user_node_authentication(self):
        """User Node ê¸°ë°˜ ì¸ì¦ í‰ê°€"""
        print("\n" + "="*80)
        print("ğŸ” USER NODE AUTHENTICATION SYSTEM EVALUATION")
        print("="*80)
        
        print(f"[Auth] Registered users: {len(self.node_manager.nodes)}")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_dataset = PalmPrintDataset(
            root_dir=self.config['dataset']['dataset_path'],
            config=self.config['dataset'],
            mode='test'
        )
        
        # ê° ì‚¬ìš©ìë³„ë¡œ ì¼ë¶€ ìƒ˜í”Œë§Œ í…ŒìŠ¤íŠ¸
        test_samples = []
        samples_per_user = 2  # ì‚¬ìš©ìë‹¹ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜
        
        for user_id in self.node_manager.nodes.keys():
            if user_id in test_dataset.label_to_indices:
                indices = test_dataset.label_to_indices[user_id]
                # í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•Šì€ ìƒ˜í”Œ ì„ íƒ
                test_indices = indices[10:10+samples_per_user]  # 11ë²ˆì§¸ ìƒ˜í”Œë¶€í„°
                for idx in test_indices:
                    if idx < len(test_dataset):
                        test_samples.append((idx, user_id))
        
        print(f"[Auth] Testing {len(test_samples)} samples...")
        
        # ì¸ì¦ í…ŒìŠ¤íŠ¸
        correct = 0
        false_accepts = 0
        false_rejects = 0
        user_accuracies = defaultdict(lambda: {'correct': 0, 'total': 0})
        
        self.predictor_model.eval()
        with torch.no_grad():
            for idx, true_user in test_samples:
                # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ
                image, _, _ = test_dataset[idx]
                image = image.unsqueeze(0).to(self.device)
                
                # íŠ¹ì§• ì¶”ì¶œ
                embedding = self.predictor_model(image)
                embedding = F.normalize(embedding, p=2, dim=1).squeeze()
                
                # 2ë‹¨ê³„ ì¸ì¦
                authenticated_user, distance, details = self.node_manager.authenticate(
                    image.squeeze(0), embedding, k_candidates=5
                )
                
                # ê²°ê³¼ í‰ê°€
                user_accuracies[true_user]['total'] += 1
                
                if authenticated_user == true_user:
                    correct += 1
                    user_accuracies[true_user]['correct'] += 1
                elif authenticated_user is not None:
                    false_accepts += 1
                else:
                    false_rejects += 1
        
        # ê²°ê³¼ ì¶œë ¥
        total_tests = len(test_samples)
        accuracy = correct / total_tests if total_tests > 0 else 0
        far = false_accepts / total_tests if total_tests > 0 else 0
        frr = false_rejects / total_tests if total_tests > 0 else 0
        
        print(f"\n[AUTH RESULTS]")
        print(f"  Total samples tested: {total_tests}")
        print(f"  Accuracy: {accuracy:.2%}")
        print(f"  FAR (False Accept Rate): {far:.2%}")
        print(f"  FRR (False Reject Rate): {frr:.2%}")
        
        # ì‚¬ìš©ìë³„ ì •í™•ë„
        print(f"\n[PER-USER ACCURACY]")
        for user_id, stats in sorted(user_accuracies.items())[:20]:  # ìƒìœ„ 20ëª…ë§Œ
            user_acc = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
            print(f"  User {user_id}: {user_acc:.1%} ({stats['correct']}/{stats['total']})")
        
        print("="*80)
    
    def calculate_eer(self, genuine_scores, impostor_scores):
        """EER ê³„ì‚° (ê°ë„ ê±°ë¦¬ ê¸°ì¤€)"""
        # ê±°ë¦¬ì´ë¯€ë¡œ ì‘ì„ìˆ˜ë¡ ë§¤ì¹˜
        thresholds = np.linspace(0, 1, 1000)
        
        far_list = []
        frr_list = []
        
        for threshold in thresholds:
            # FAR: impostorê°€ thresholdë³´ë‹¤ ì‘ì€ ë¹„ìœ¨
            far = np.mean(impostor_scores < threshold)
            # FRR: genuineì´ thresholdë³´ë‹¤ í° ë¹„ìœ¨
            frr = np.mean(genuine_scores > threshold)
            
            far_list.append(far)
            frr_list.append(frr)
        
        far_list = np.array(far_list)
        frr_list = np.array(frr_list)
        
        # EER ì°¾ê¸°
        diff = np.abs(far_list - frr_list)
        eer_idx = np.argmin(diff)
        eer = (far_list[eer_idx] + frr_list[eer_idx]) / 2
        eer_threshold = thresholds[eer_idx]
        
        return eer, eer_threshold


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì • íŒŒì¼ ê²½ë¡œ
    config_path = "config/adapt_config.yaml"
    
    # ì‹œìŠ¤í…œ ìƒì„± ë° ì‹¤í–‰
    system = EnhancedCoCoNutSystem(config_path)
    system.run_batch_continual_learning()


if __name__ == "__main__":
    main()