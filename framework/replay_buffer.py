# framework/replay_buffer.py - CCNet ìŠ¤íƒ€ì¼ë¡œ ìˆ˜ì •ëœ ë²„ì „

"""
CoCoNut Replay Buffer with Loop Closure Support

ğŸ”¥ FEATURES:
- Priority queue for loop closure samples
- User-specific sample retrieval
- Enhanced sampling strategies
- Even-count maintenance for SupConLoss
- CCNet-style pair handling
"""

import os
import pickle
import random
from pathlib import Path
from typing import List, Tuple, Dict, Optional, Set
from collections import defaultdict

try:
    import faiss
    import numpy as np
    FAISS_AVAILABLE = True
    print("[Buffer] ğŸš€ Faiss available - Buffer optimization enabled")
except ImportError:
    FAISS_AVAILABLE = False
    print("[Buffer] âš ï¸ Faiss not found - using PyTorch fallback")
    import numpy as np

import torch
import torch.nn.functional as F
from PIL import Image

class ReplayBuffer:
    def __init__(self, config, storage_dir: Path, feature_dimension: int = 128):
        """ë¦¬í”Œë ˆì´ ë²„í¼ with Loop Closure support + CCNet style"""
        self.config = config
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ë³¸ ì„¤ì •
        self.buffer_size = self.config.max_buffer_size
        self.similarity_threshold = self.config.similarity_threshold
        self.feature_dimension = feature_dimension
        self.samples_per_user_limit = getattr(self.config, 'samples_per_user_limit', 4)  # ì§ìˆ˜ë¡œ ì„¤ì •
        self.min_samples_new_user = getattr(self.config, 'min_samples_new_user', 2)     # ì§ìˆ˜ë¡œ ì„¤ì •
        
        # Faiss ì¸ë±ìŠ¤ ë° ì €ì¥ì†Œ
        self.image_storage = []
        self.faiss_index = None
        self.stored_embeddings = []
        self.metadata = {}
        self.feature_extractor = None
        self.device = 'cpu'
        
        # í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ë¹„ìœ¨
        self.hard_negative_ratio = 0.3
        
        # ğŸ”¥ Loop Closure Priority Queue
        self.priority_queue = []  # ìš°ì„ ìˆœìœ„ ìƒ˜í”Œë“¤
        self.priority_users = set()  # ìš°ì„ ìˆœìœ„ ì‚¬ìš©ì IDë“¤
        
        # ë°ì´í„° ì¦ê°• ì„¤ì •
        self.enable_augmentation = False
        self.aug_config = None
        self._setup_augmentation_transforms()
        
        # ìƒíƒœ ë¡œë“œ
        self.state_file = self.storage_dir / 'buffer_state.pkl'
        self._load_state()
        
        print(f"[Buffer] ğŸ¥¥ Replay Buffer initialized (CCNet style)")
        print(f"[Buffer] Max size: {self.buffer_size}")
        print(f"[Buffer] Per-user limit: {self.samples_per_user_limit} (even count)")
        print(f"[Buffer] Min samples for new user: {self.min_samples_new_user}")
        print(f"[Buffer] Current size: {len(self.image_storage)}")
        print(f"[Buffer] ğŸ”¥ Loop Closure support: ENABLED")

    def add_if_diverse(self, image: torch.Tensor, user_id: int, embedding: torch.Tensor = None):
        """
        ë‹¤ì–‘ì„± ê¸°ë°˜ ì¶”ê°€ - ì§ìˆ˜ ìœ ì§€ ê³ ë ¤
        
        Args:
            image: ì´ë¯¸ì§€
            user_id: ì‚¬ìš©ì ID
            embedding: ì´ë¯¸ ê³„ì‚°ëœ ì„ë² ë”© (ì—†ìœ¼ë©´ ê³„ì‚°)
        """
        # ì‚¬ìš©ìë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸
        user_samples = [item for item in self.image_storage if item['user_id'] == user_id]
        current_count = len(user_samples)
        
        if current_count >= self.samples_per_user_limit:
            print(f"[Buffer] User {user_id} already has {current_count} samples (limit: {self.samples_per_user_limit})")
            return False
        
        # ì„ë² ë”© ê³„ì‚°
        if embedding is None:
            with torch.no_grad():
                embedding = self._extract_feature(image)
        
        # í™€ìˆ˜ì¸ ê²½ìš° ë¬´ì¡°ê±´ ì¶”ê°€ (ì§ìˆ˜ë¡œ ë§Œë“¤ê¸°)
        if current_count % 2 == 1:
            # ë²„í¼ ê³µê°„ í™•ë³´
            if len(self.image_storage) >= self.buffer_size:
                self._remove_least_diverse_even()
            
            self._store_sample(image, user_id, embedding)
            return True
        
        # ì§ìˆ˜ì¸ ê²½ìš° ë‹¤ì–‘ì„± ì²´í¬
        if current_count > 0:
            max_similarity = self._compute_max_similarity_to_user(embedding, user_id)
            
            if max_similarity >= self.similarity_threshold:
                print(f"[Buffer] Sample too similar ({max_similarity:.3f} >= {self.similarity_threshold})")
                return False
        
        # ë²„í¼ ê³µê°„ í™•ë³´
        if len(self.image_storage) >= self.buffer_size:
            self._remove_least_diverse_even()
        
        # ì €ì¥
        self._store_sample(image, user_id, embedding)
        return True

    def add_sample_direct(self, image: torch.Tensor, user_id: int, embedding: torch.Tensor):
        """ì§ì ‘ ìƒ˜í”Œ ì¶”ê°€ (ë‹¤ì–‘ì„± ì²´í¬ ì—†ì´)"""
        # ë²„í¼ ê³µê°„ í™•ë³´
        if len(self.image_storage) >= self.buffer_size:
            self._remove_least_diverse_even()
        
        # ì €ì¥
        self._store_sample(image, user_id, embedding)
        return True

    def sample_for_training(self, num_samples: int, current_embeddings: List[torch.Tensor], 
                          current_user_id: int) -> Tuple[List, List]:
        """í•™ìŠµì„ ìœ„í•œ ìƒ˜í”Œë§ - ğŸ”¥ Loop Closure ìš°ì„ ìˆœìœ„ ì§€ì›"""
        if len(self.image_storage) == 0:
            return [], []
        
        sampled_images = []
        sampled_labels = []
        used_indices = set()
        
        # ğŸ”¥ 1. Priority Queue ì²˜ë¦¬ (Loop Closure)
        if self.priority_queue:
            print(f"[Buffer] Processing {len(self.priority_queue)} priority samples")
            
            for priority_item in self.priority_queue[:num_samples]:
                sampled_images.append(priority_item['image'])
                sampled_labels.append(priority_item['user_id'])
                
            # ì‚¬ìš©í•œ ê²ƒë“¤ì€ ì œê±°
            self.priority_queue = self.priority_queue[len(sampled_images):]
            
            if len(sampled_images) >= num_samples:
                return sampled_images[:num_samples], sampled_labels[:num_samples]
        
        # 2. í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ë§ˆì´ë‹
        remaining_samples = num_samples - len(sampled_images)
        num_hard = int(remaining_samples * self.hard_negative_ratio)
        
        if num_hard > 0 and current_embeddings:
            hard_samples = self._mine_hard_negatives_batch(
                current_embeddings, current_user_id, num_hard
            )
            
            for item in hard_samples:
                if len(sampled_images) < num_samples:
                    sampled_images.append(item['image'])
                    sampled_labels.append(item['user_id'])
                    used_indices.add(item['id'])
        
        # 3. ëœë¤ ìƒ˜í”Œë§
        remaining_samples = num_samples - len(sampled_images)
        if remaining_samples > 0:
            available_indices = []
            for i, storage_item in enumerate(self.image_storage):
                if storage_item['id'] not in used_indices:
                    available_indices.append(i)
            
            if available_indices:
                random_indices = random.choices(available_indices, 
                                              k=min(remaining_samples, len(available_indices)))
                
                for idx in random_indices:
                    if len(sampled_images) < num_samples:
                        item = self.image_storage[idx]
                        sampled_images.append(item['image'])
                        sampled_labels.append(item['user_id'])
        
        print(f"[Buffer] Sampled {len(sampled_images)} samples: "
              f"{len(self.priority_queue)} priority, "
              f"{num_hard} hard, "
              f"{len(sampled_images) - len(self.priority_queue) - num_hard} random")
        
        return sampled_images, sampled_labels

    def sample_for_training_even(self, num_samples: int, current_user_id: int) -> Tuple[List, List]:
        """
        í•™ìŠµì„ ìœ„í•œ ìƒ˜í”Œë§ - CCNet ìŠ¤íƒ€ì¼ (ì§ìˆ˜ ë³´ì¥)
        
        Args:
            num_samples: ìš”ì²­ëœ ìƒ˜í”Œ ìˆ˜
            current_user_id: í˜„ì¬ ì‚¬ìš©ì ID (ì œì™¸ìš©)
            
        Returns:
            (images, labels) - ì§ìˆ˜ê°œ ë³´ì¥
        """
        if len(self.image_storage) == 0:
            return [], []
        
        sampled_images = []
        sampled_labels = []
        used_indices = set()
        
        # 1. Priority Queue ì²˜ë¦¬
        if self.priority_queue:
            for priority_item in self.priority_queue[:num_samples]:
                sampled_images.append(priority_item['image'])
                sampled_labels.append(priority_item['user_id'])
                
            self.priority_queue = self.priority_queue[len(sampled_images):]
            
            if len(sampled_images) >= num_samples:
                return self._ensure_even_count(sampled_images[:num_samples], 
                                              sampled_labels[:num_samples])
        
        # 2. ë¼ë²¨ë³„ ê·¸ë£¹í™”
        label_groups = defaultdict(list)
        for i, item in enumerate(self.image_storage):
            if item['user_id'] != current_user_id:  # í˜„ì¬ ì‚¬ìš©ì ì œì™¸
                label_groups[item['user_id']].append(i)
        
        # 3. ê° ë¼ë²¨ì—ì„œ ì§ìˆ˜ê°œì”© ìƒ˜í”Œë§
        for user_id, indices in label_groups.items():
            if len(sampled_images) >= num_samples:
                break
                
            if len(indices) >= 2:
                # ì§ìˆ˜ê°œ ì„ íƒ
                num_to_sample = min(len(indices) // 2 * 2, 4)  # ìµœëŒ€ 4ê°œ
                selected_indices = random.sample(indices, num_to_sample)
                
                for idx in selected_indices:
                    if len(sampled_images) < num_samples:
                        item = self.image_storage[idx]
                        sampled_images.append(item['image'])
                        sampled_labels.append(item['user_id'])
                        used_indices.add(idx)
        
        # 4. ë¶€ì¡±í•˜ë©´ ì¶”ê°€ ìƒ˜í”Œë§
        remaining = num_samples - len(sampled_images)
        if remaining > 0:
            available_indices = [i for i in range(len(self.image_storage)) 
                               if i not in used_indices and 
                               self.image_storage[i]['user_id'] != current_user_id]
            
            if available_indices:
                # ì§ìˆ˜ê°œë¡œ ë§ì¶”ê¸°
                if remaining % 2 == 1:
                    remaining += 1
                    
                additional = random.sample(available_indices, 
                                         min(remaining, len(available_indices)))
                
                for idx in additional:
                    if len(sampled_images) < num_samples:
                        item = self.image_storage[idx]
                        sampled_images.append(item['image'])
                        sampled_labels.append(item['user_id'])
        
        # 5. ìµœì¢…ì ìœ¼ë¡œ ì§ìˆ˜ë¡œ ì¡°ì •
        return self._ensure_even_count(sampled_images, sampled_labels)

    def _ensure_even_count(self, images: List, labels: List) -> Tuple[List, List]:
        """ì§ìˆ˜ê°œë¡œ ë³´ì¥"""
        if len(images) % 2 == 1 and len(images) > 0:
            images.pop()
            labels.pop()
        
        print(f"[Buffer] Sampled {len(images)} samples (even count ensured)")
        return images, labels

    def _remove_least_diverse_even(self):
        """ë‹¤ì–‘ì„± ê¸°ë°˜ ì‚­ì œ - ì§ìˆ˜ ìœ ì§€"""
        if len(self.image_storage) < 2:
            return
        
        # ì‚¬ìš©ìë³„ ê·¸ë£¹í™”
        user_samples = defaultdict(list)
        for i, item in enumerate(self.image_storage):
            user_samples[item['user_id']].append(i)
        
        # ì‚­ì œ ëŒ€ìƒ ì„ ì •
        candidate_users = []
        for user_id, indices in user_samples.items():
            if user_id in self.priority_users or len(indices) < 2:
                continue
                
            # í‰ê·  ë‹¤ì–‘ì„± ê³„ì‚°
            avg_div = self._calculate_user_average_diversity(indices)
            candidate_users.append((user_id, indices, avg_div))
        
        if not candidate_users:
            # ëª¨ë“  ì‚¬ìš©ìê°€ ë³´í˜¸ë˜ê±°ë‚˜ 1ê°œì”©ë§Œ ìˆìŒ
            # ê°€ì¥ ì˜¤ë˜ëœ ë¹„ìš°ì„ ìˆœìœ„ ì‚¬ìš©ì ì°¾ê¸°
            for user_id, indices in user_samples.items():
                if user_id not in self.priority_users and len(indices) >= 2:
                    candidate_users.append((user_id, indices, 1.0))
                    break
        
        if not candidate_users:
            print("[Buffer] No removable samples while maintaining even counts")
            return
        
        # ê°€ì¥ ë‹¤ì–‘ì„± ë‚®ì€ ì‚¬ìš©ì ì„ íƒ
        candidate_users.sort(key=lambda x: x[2])
        selected_user, indices, _ = candidate_users[0]
        
        # ì‚­ì œ ê°œìˆ˜ ê²°ì • (ì§ìˆ˜ ìœ ì§€)
        current_count = len(indices)
        if current_count % 2 == 0:
            # ì§ìˆ˜ â†’ 2ê°œ ì‚­ì œ
            num_to_remove = 2
        else:
            # í™€ìˆ˜ â†’ 1ê°œ ì‚­ì œ (ì§ìˆ˜ë¡œ)
            num_to_remove = 1
        
        # ê°€ì¥ ìœ ì‚¬í•œ ìƒ˜í”Œë“¤ ì°¾ê¸°
        if num_to_remove == 1:
            remove_indices = [self._find_most_redundant_single(indices)]
        else:
            remove_indices = self._find_most_similar_pair(indices)
        
        # ì‚­ì œ ì‹¤í–‰
        for idx in sorted(remove_indices, reverse=True):
            removed_id = self.image_storage[idx]['id']
            del self.image_storage[idx]
            del self.stored_embeddings[idx]
            if removed_id in self.metadata:
                del self.metadata[removed_id]
        
        print(f"[Buffer] Removed {num_to_remove} samples from user {selected_user} "
              f"({current_count} â†’ {current_count-num_to_remove})")
        
        self._rebuild_faiss_index()

    def _find_most_redundant_single(self, indices: List[int]) -> int:
        """ê°€ì¥ ì¤‘ë³µëœ ë‹¨ì¼ ìƒ˜í”Œ ì°¾ê¸°"""
        max_avg_sim = -1
        most_redundant = indices[0]
        
        for i, idx in enumerate(indices):
            similarities = []
            for j, other_idx in enumerate(indices):
                if i != j:
                    sim = self._compute_similarity_by_idx(idx, other_idx)
                    similarities.append(sim)
            
            avg_sim = np.mean(similarities) if similarities else 0
            if avg_sim > max_avg_sim:
                max_avg_sim = avg_sim
                most_redundant = idx
        
        return most_redundant

    def _find_most_similar_pair(self, indices: List[int]) -> List[int]:
        """ê°€ì¥ ìœ ì‚¬í•œ í˜ì–´ ì°¾ê¸°"""
        max_sim = -1
        best_pair = [indices[0], indices[1]] if len(indices) >= 2 else indices[:1]
        
        for i in range(len(indices)):
            for j in range(i + 1, len(indices)):
                sim = self._compute_similarity_by_idx(indices[i], indices[j])
                if sim > max_sim:
                    max_sim = sim
                    best_pair = [indices[i], indices[j]]
        
        return best_pair

    def _compute_similarity_by_idx(self, idx1: int, idx2: int) -> float:
        """ì¸ë±ìŠ¤ë¡œ ìœ ì‚¬ë„ ê³„ì‚°"""
        emb1 = torch.tensor(self.stored_embeddings[idx1])
        emb2 = torch.tensor(self.stored_embeddings[idx2])
        
        similarity = F.cosine_similarity(
            emb1.unsqueeze(0),
            emb2.unsqueeze(0)
        ).item()
        
        return similarity

    def _calculate_user_average_diversity(self, indices: List[int]) -> float:
        """ì‚¬ìš©ìì˜ í‰ê·  ë‹¤ì–‘ì„± ê³„ì‚°"""
        if len(indices) < 2:
            return 1.0  # ë†’ì€ ë‹¤ì–‘ì„±ìœ¼ë¡œ ê°€ì •
        
        total_sim = 0
        count = 0
        
        for i in range(len(indices)):
            for j in range(i + 1, len(indices)):
                sim = self._compute_similarity_by_idx(indices[i], indices[j])
                total_sim += sim
                count += 1
        
        avg_sim = total_sim / count if count > 0 else 0
        return 1 - avg_sim  # ë‹¤ì–‘ì„± = 1 - ìœ ì‚¬ë„

    def add_priority_samples(self, user_ids: List[int], priority_weight: float = 2.0):
        """
        ğŸ”¥ Loop Closureìš© ìš°ì„ ìˆœìœ„ ìƒ˜í”Œ ì¶”ê°€
        
        Args:
            user_ids: ìš°ì„ ìˆœìœ„ë¡œ ì¶”ê°€í•  ì‚¬ìš©ì IDë“¤
            priority_weight: ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜
        """
        print(f"[Buffer] Adding priority samples for users: {user_ids}")
        
        for user_id in user_ids:
            user_samples = self.get_user_samples(user_id)
            
            for sample_dict in user_samples:
                # ìš°ì„ ìˆœìœ„ íì— ì¶”ê°€
                priority_item = sample_dict.copy()
                priority_item['priority_weight'] = priority_weight
                self.priority_queue.append(priority_item)
            
            self.priority_users.add(user_id)
            print(f"[Buffer] Added {len(user_samples)} priority samples for user {user_id}")
        
        # ìš°ì„ ìˆœìœ„ í ì •ë ¬ (ê°€ì¤‘ì¹˜ ë†’ì€ ê²ƒë¶€í„°)
        self.priority_queue.sort(key=lambda x: x.get('priority_weight', 1.0), reverse=True)

    def get_user_samples(self, user_id: int) -> List[Dict]:
        """
        ğŸ”¥ íŠ¹ì • ì‚¬ìš©ìì˜ ëª¨ë“  ìƒ˜í”Œ ë°˜í™˜
        
        Returns:
            List of sample dictionaries
        """
        user_samples = []
        for item in self.image_storage:
            if item['user_id'] == user_id:
                user_samples.append(item)
        return user_samples

    def get_user_sample_images(self, user_id: int) -> List[torch.Tensor]:
        """
        ğŸ”¥ íŠ¹ì • ì‚¬ìš©ìì˜ ì´ë¯¸ì§€ë§Œ ë°˜í™˜ (Loop Closureìš©)
        
        Returns:
            List of image tensors
        """
        return [item['image'] for item in self.image_storage if item['user_id'] == user_id]

    def clear_priority_queue(self):
        """ğŸ”¥ ìš°ì„ ìˆœìœ„ í ì´ˆê¸°í™”"""
        self.priority_queue = []
        self.priority_users.clear()
        print("[Buffer] Priority queue cleared")

    def _mine_hard_negatives_batch(self, query_embeddings: List[torch.Tensor], 
                                  exclude_user: int, num_samples: int) -> List[Dict]:
        """ë°°ì¹˜ ì¿¼ë¦¬ë¡œ í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ë§ˆì´ë‹"""
        if not self.faiss_index or self.faiss_index.ntotal == 0:
            return []
        
        # í‰ê·  ì„ë² ë”©ìœ¼ë¡œ ì¿¼ë¦¬
        query_tensor = torch.stack(query_embeddings).mean(dim=0, keepdim=True)
        query_np = query_tensor.cpu().numpy().astype('float32')
        
        if len(query_np.shape) == 3:
            # (1, 1, feature_dim) -> (1, feature_dim)
            query_np = query_np.squeeze(0)
        elif len(query_np.shape) == 1:
            # (feature_dim,) -> (1, feature_dim)
            query_np = query_np.reshape(1, -1)
        
        faiss.normalize_L2(query_np)
        
        # FAISS ê²€ìƒ‰
        k = min(num_samples * 3, self.faiss_index.ntotal)
        similarities, indices = self.faiss_index.search(query_np, k)
        
        # ë‹¤ë¥¸ ì‚¬ìš©ìì˜ ì–´ë ¤ìš´ ìƒ˜í”Œë“¤ ì„ íƒ
        hard_samples = []
        for idx in indices[0]:
            if idx < len(self.image_storage):
                item = self.image_storage[idx]
                if item['user_id'] != exclude_user:
                    hard_samples.append(item)
                    if len(hard_samples) >= num_samples:
                        break
        
        return hard_samples

    def _compute_max_similarity_to_user(self, embedding: torch.Tensor, user_id: int) -> float:
        """íŠ¹ì • ì‚¬ìš©ìì˜ ìƒ˜í”Œë“¤ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„"""
        user_indices = [i for i, item in enumerate(self.image_storage) 
                       if item['user_id'] == user_id]
        
        if not user_indices:
            return 0.0
        
        if FAISS_AVAILABLE and self.faiss_index:
            # FAISS ì‚¬ìš©
            query = embedding.cpu().numpy().astype('float32')
            if len(query.shape) == 1:
                query = query.reshape(1, -1)
            elif len(query.shape) == 3:
                query = query.squeeze(0)
            faiss.normalize_L2(query)
            
            # ì‚¬ìš©ì ìƒ˜í”Œë“¤ë§Œ ê²€ìƒ‰í•˜ë„ë¡ ì„ì‹œ ì¸ë±ìŠ¤ ìƒì„±
            user_embeddings = np.array([self.stored_embeddings[i] for i in user_indices])
            temp_index = faiss.IndexFlatIP(self.feature_dimension)
            temp_index.add(user_embeddings)
            
            similarities, _ = temp_index.search(query, 1)
            return similarities[0][0]
        else:
            # PyTorch í´ë°±
            max_sim = 0.0
            query_norm = F.normalize(embedding.flatten(), dim=0)
            
            for idx in user_indices:
                stored_emb = torch.tensor(self.stored_embeddings[idx])
                stored_norm = F.normalize(stored_emb.flatten(), dim=0)
                sim = torch.cosine_similarity(query_norm.unsqueeze(0), 
                                            stored_norm.unsqueeze(0)).item()
                max_sim = max(max_sim, sim)
            
            return max_sim

    def _store_sample(self, image: torch.Tensor, user_id: int, embedding: torch.Tensor):
        """ìƒ˜í”Œ ì €ì¥"""
        unique_id = len(self.image_storage)
        
        # ì´ë¯¸ì§€ ì €ì¥
        self.image_storage.append({
            'image': image.cpu().clone(),
            'user_id': user_id,
            'id': unique_id,
            'timestamp': len(self.image_storage)  # ì¶”ê°€ ìˆœì„œ
        })
        
        # ì„ë² ë”© ì €ì¥
        embedding_np = embedding.cpu().numpy().astype('float32')
        
        if len(embedding_np.shape) == 1:
            embedding_np = embedding_np.reshape(1, -1)
        
        if FAISS_AVAILABLE:
            faiss.normalize_L2(embedding_np)
        
        self.stored_embeddings.append(embedding_np.squeeze().copy())
        
        # Faiss ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        if self.faiss_index is None:
            self._initialize_faiss()
        
        if FAISS_AVAILABLE and self.faiss_index is not None:
            self.faiss_index.add_with_ids(embedding_np, np.array([unique_id]))
        
        # ë©”íƒ€ë°ì´í„°
        self.metadata[unique_id] = {
            'user_id': user_id,
            'priority': user_id in self.priority_users
        }
        
        # í˜„ì¬ ì‚¬ìš©ìì˜ ìƒ˜í”Œ ìˆ˜ í™•ì¸
        user_count = sum(1 for item in self.image_storage if item['user_id'] == user_id)
        
        print(f"[Buffer] Stored sample {unique_id} for user {user_id}. "
              f"Buffer: {len(self.image_storage)}/{self.buffer_size}, "
              f"User samples: {user_count}")

    def update_hard_negative_ratio(self, ratio: float):
        """í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ë¹„ìœ¨ ì—…ë°ì´íŠ¸"""
        self.hard_negative_ratio = ratio
        print(f"[Buffer] Hard negative ratio updated to {ratio:.1%}")

    def set_feature_extractor(self, model):
        """íŠ¹ì§• ì¶”ì¶œê¸° ì„¤ì •"""
        self.feature_extractor = model
        if model is not None:
            self.device = next(model.parameters()).device
            print(f"[Buffer] Feature extractor set (device: {self.device})")

    def _extract_feature(self, image: torch.Tensor) -> torch.Tensor:
        """íŠ¹ì§• ì¶”ì¶œ"""
        if self.feature_extractor is None:
            raise ValueError("Feature extractor not set")
        
        image = image.to(self.device)
        if len(image.shape) == 3:
            image = image.unsqueeze(0)
        
        with torch.no_grad():
            features = self.feature_extractor.getFeatureCode(image)
        
        return features.squeeze(0)

    def _initialize_faiss(self):
        """Faiss ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        if FAISS_AVAILABLE:
            index = faiss.IndexFlatIP(self.feature_dimension)
            self.faiss_index = faiss.IndexIDMap(index)
            print(f"[Buffer] Faiss index initialized")
        else:
            self.faiss_index = None

    def _rebuild_faiss_index(self):
        """Faiss ì¸ë±ìŠ¤ ì¬êµ¬ì„±"""
        if not FAISS_AVAILABLE or not self.stored_embeddings:
            return
        
        self._initialize_faiss()
        
        for i, (embedding, item) in enumerate(zip(self.stored_embeddings, self.image_storage)):
            embedding_np = np.array(embedding).astype('float32')
            if len(embedding_np.shape) == 1:
                embedding_np = embedding_np.reshape(1, -1)
            if FAISS_AVAILABLE:
                faiss.normalize_L2(embedding_np)
            self.faiss_index.add_with_ids(embedding_np, np.array([item['id']]))
        
        print(f"[Buffer] Faiss index rebuilt with {len(self.stored_embeddings)} samples")

    def _setup_augmentation_transforms(self):
        """ë°ì´í„° ì¦ê°• ì„¤ì •"""
        self.augmentation_transforms = None

    def get_statistics(self) -> Dict:
        """ë²„í¼ í†µê³„ - ğŸ”¥ Loop Closure ì •ë³´ ì¶”ê°€"""
        user_distribution = {}
        even_count_users = 0
        
        for item in self.image_storage:
            user_id = item['user_id']
            user_distribution[user_id] = user_distribution.get(user_id, 0) + 1
        
        # ì§ìˆ˜ ê°œìˆ˜ë¥¼ ê°€ì§„ ì‚¬ìš©ì ìˆ˜ ê³„ì‚°
        for count in user_distribution.values():
            if count % 2 == 0:
                even_count_users += 1
        
        return {
            'total_samples': len(self.image_storage),
            'unique_users': len(user_distribution),
            'user_distribution': user_distribution,
            'buffer_utilization': len(self.image_storage) / self.buffer_size,
            'avg_samples_per_user': len(self.image_storage) / len(user_distribution) if user_distribution else 0,
            'priority_queue_size': len(self.priority_queue),
            'priority_users': list(self.priority_users),
            'even_count_users': even_count_users,
            'even_count_percentage': even_count_users / len(user_distribution) if user_distribution else 0
        }

    def _save_state(self):
        """ìƒíƒœ ì €ì¥ - ğŸ”¥ ìš°ì„ ìˆœìœ„ ì •ë³´ í¬í•¨"""
        save_data = {
            'image_storage': self.image_storage,
            'stored_embeddings': self.stored_embeddings,
            'metadata': self.metadata,
            'feature_dim': self.feature_dimension,
            'priority_queue': self.priority_queue,
            'priority_users': list(self.priority_users),
            'buffer_config': {
                'max_size': self.buffer_size,
                'samples_per_user_limit': self.samples_per_user_limit,
                'similarity_threshold': self.similarity_threshold,
                'hard_negative_ratio': self.hard_negative_ratio
            }
        }
        
        with open(self.state_file, 'wb') as f:
            pickle.dump(save_data, f)
        
        stats = self.get_statistics()
        print(f"[Buffer] State saved: {len(self.image_storage)} samples, "
              f"{len(self.priority_queue)} priority items, "
              f"{stats['even_count_percentage']:.1%} even count users")

    def _load_state(self):
        """ìƒíƒœ ë¡œë“œ - ğŸ”¥ ìš°ì„ ìˆœìœ„ ì •ë³´ í¬í•¨"""
        if not self.state_file.exists():
            return
        
        try:
            with open(self.state_file, 'rb') as f:
                save_data = pickle.load(f)
            
            self.image_storage = save_data.get('image_storage', [])
            self.stored_embeddings = save_data.get('stored_embeddings', [])
            self.metadata = save_data.get('metadata', {})
            self.priority_queue = save_data.get('priority_queue', [])
            self.priority_users = set(save_data.get('priority_users', []))
            
            # ì„¤ì • ë³µì›
            buffer_config = save_data.get('buffer_config', {})
            if buffer_config:
                self.hard_negative_ratio = buffer_config.get('hard_negative_ratio', 0.3)
            
            if self.image_storage:
                self._rebuild_faiss_index()
            
            stats = self.get_statistics()
            print(f"[Buffer] State loaded: {len(self.image_storage)} samples, "
                  f"{len(self.priority_queue)} priority items, "
                  f"{stats['even_count_percentage']:.1%} even count users")
        except Exception as e:
            print(f"[Buffer] Failed to load state: {e}")
            print("[Buffer] Starting with empty buffer")