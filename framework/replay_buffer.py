# framework/replay_buffer.py - Hard Mining + 3ê°€ì§€ ì¦ê°• í†µí•©
"""
CoCoNut Intelligent Replay Buffer with Advanced Sampling

CORE FEATURES:
- Diversity-based sample selection using Faiss similarity search
- Hard sample mining with fixed ratio
- 3-type augmentation: Geometric + Resolution + Noise
- Complete state management for checkpoint resume
"""

import os
import pickle
import random
from pathlib import Path

import faiss
import numpy as np
import torch
import torchvision.transforms as transforms
from PIL import Image

class CoconutReplayBuffer:
    def __init__(self, config, storage_dir: Path, feature_dimension: int = 2048):
        """
        ì§€ëŠ¥í˜• ë¦¬í”Œë ˆì´ ë²„í¼ ì´ˆê¸°í™”
        """
        self.config = config
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        self.buffer_size = self.config.max_buffer_size
        self.similarity_threshold = self.config.similarity_threshold
        self.feature_dimension = feature_dimension

        # Faiss ì¸ë±ìŠ¤ ë° ì €ì¥ì†Œ
        self.image_storage = []
        self.faiss_index = None
        self.stored_embeddings = []
        self.metadata = {}
        self.feature_extractor = None

        # ğŸ”¥ Hard Mining ì„¤ì • (ë‚˜ì¤‘ì— CoconutSystemì—ì„œ ì„¤ì •ë¨)
        self.enable_hard_mining = False  # ê¸°ë³¸ê°’
        self.hard_ratio = 0.3  # ê¸°ë³¸ê°’
        
        # ğŸ”¥ ë°ì´í„° ì¦ê°• ì„¤ì • (ë‚˜ì¤‘ì— CoconutSystemì—ì„œ ì„¤ì •ë¨)
        self.enable_augmentation = False  # ê¸°ë³¸ê°’
        self.aug_config = None
        self._setup_augmentation_transforms()
        
        # ìƒíƒœ íŒŒì¼ ê²½ë¡œ
        self.state_file = self.storage_dir / 'buffer_state.pkl'
        self._load_state()

        print(f"[Buffer] ğŸ¥¥ CoCoNut Replay Buffer initialized")
        print(f"[Buffer] Max size: {self.buffer_size}, Threshold: {self.similarity_threshold}")
        print(f"[Buffer] Hard mining: {self.enable_hard_mining} (ratio: {self.hard_ratio})")
        print(f"[Buffer] Augmentation: {self.enable_augmentation}")
        print(f"[Buffer] Current size: {len(self.image_storage)}")

    def update_hard_mining_config(self, enable_hard_mining, hard_ratio):
        """ğŸ”¥ Hard Mining ì„¤ì • ì—…ë°ì´íŠ¸ (CoconutSystemì—ì„œ í˜¸ì¶œ)"""
        self.enable_hard_mining = enable_hard_mining
        self.hard_ratio = hard_ratio
        print(f"[Buffer] ğŸ”¥ Hard Mining updated: {self.enable_hard_mining} (ratio: {self.hard_ratio})")

    def update_augmentation_config(self, enable_augmentation, aug_config):
        """ğŸ”¥ ë°ì´í„° ì¦ê°• ì„¤ì • ì—…ë°ì´íŠ¸ (CoconutSystemì—ì„œ í˜¸ì¶œ)"""
        self.enable_augmentation = enable_augmentation
        self.aug_config = aug_config
        self._setup_augmentation_transforms()
        print(f"[Buffer] ğŸ¨ Augmentation updated: {self.enable_augmentation}")

    def _setup_augmentation_transforms(self):
        """3ê°€ì§€ ì¦ê°• ë³€í™˜ ì„¤ì •"""
        if not self.enable_augmentation or not self.aug_config:
            self.geometric_transform = None
            self.noise_transform = None
            return
            
        # 1. ê¸°í•˜í•™ì  ë³€í™˜
        if getattr(self.aug_config, 'enable_geometric', False):
            max_rotation = getattr(self.aug_config, 'max_rotation_degrees', 3)
            max_translation = getattr(self.aug_config, 'max_translation_ratio', 0.05)
            
            self.geometric_transform = transforms.RandomAffine(
                degrees=(-max_rotation, max_rotation),
                translate=(max_translation, max_translation),
                interpolation=transforms.InterpolationMode.BILINEAR
            )
        else:
            self.geometric_transform = None
            
        # 2. í•´ìƒë„ ì ì‘ - ë™ì ìœ¼ë¡œ ì²˜ë¦¬
        self.resolution_config = {
            'enable': getattr(self.aug_config, 'enable_resolution_adaptation', False),
            'probability': getattr(self.aug_config, 'resolution_probability', 0.3),
            'intermediate_sizes': getattr(self.aug_config, 'intermediate_resolutions', [[64, 64], [96, 96], [160, 160]]),
            'methods': getattr(self.aug_config, 'resize_methods', ['bilinear', 'bicubic'])
        }
        
        # 3. ë…¸ì´ì¦ˆ - ë™ì ìœ¼ë¡œ ì²˜ë¦¬
        self.noise_config = {
            'enable': getattr(self.aug_config, 'enable_noise', False),
            'probability': getattr(self.aug_config, 'noise_probability', 0.3),
            'std_range': getattr(self.aug_config, 'noise_std_range', [0.01, 0.03])
        }

    def set_feature_extractor(self, model):
        """íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•œ ëª¨ë¸ ì„¤ì •"""
        self.feature_extractor = model

    def _initialize_faiss(self):
        """Faiss ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        index = faiss.IndexFlatIP(self.feature_dimension)
        self.faiss_index = faiss.IndexIDMap(index)
        print(f"[Buffer] Faiss index initialized with dimension {self.feature_dimension}")

    def _extract_feature_for_diversity(self, image):
        """ë‹¤ì–‘ì„± ì¸¡ì •ì„ ìœ„í•œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ"""
        if self.feature_extractor is None:
            raise ValueError("Feature extractor not set")
        
        if len(image.shape) == 3:
            image = image.unsqueeze(0)
        
        with torch.no_grad():
            features = self.feature_extractor.getFeatureCode(image)
        
        return features

    def add(self, image: torch.Tensor, user_id: int):
        """ìƒˆë¡œìš´ ê²½í—˜ì„ ë²„í¼ì— ì¶”ê°€ (ë‹¤ì–‘ì„± ê¸°ë°˜)"""
        with torch.no_grad():
            embedding = self._extract_feature_for_diversity(image)
            embedding_np = embedding.cpu().numpy().astype('float32')
            faiss.normalize_L2(embedding_np)

        if self.faiss_index is None:
            self._initialize_faiss()

        # ë‹¤ì–‘ì„± í™•ì¸
        if self.faiss_index.ntotal == 0:
            max_similarity = 0.0
        else:
            distances, _ = self.faiss_index.search(embedding_np, k=1)
            max_similarity = distances[0][0]

        # ìƒˆë¡œìš´ ê²½í—˜ì´ë©´ ì €ì¥
        if max_similarity < self.similarity_threshold:
            if len(self.image_storage) >= self.buffer_size:
                self._cull()
            
            unique_id = len(self.image_storage)
            self.image_storage.append({
                'image': image.cpu().clone(),
                'user_id': user_id,
                'id': unique_id
            })
            
            self.stored_embeddings.append(embedding_np.copy())
            self.faiss_index.add_with_ids(embedding_np, np.array([unique_id]))
            self.metadata[unique_id] = {'user_id': user_id}
            
            print(f"[Buffer] âœ… Added diverse sample (ID: {unique_id}, User: {user_id}). "
                  f"Buffer: {len(self.image_storage)}/{self.buffer_size}")
        else:
            print(f"[Buffer] âš ï¸ Similar sample skipped (similarity: {max_similarity:.4f} >= {self.similarity_threshold})")

    def _cull(self):
        """ê°€ì¥ ì¤‘ë³µë˜ëŠ” ë°ì´í„° ì œê±°"""
        if self.faiss_index.ntotal < 2:
            return

        print(f"[Buffer] ğŸ”„ Buffer full. Finding most redundant sample...")
        
        if len(self.stored_embeddings) == 0:
            return
        
        all_vectors = np.vstack(self.stored_embeddings)
        k = min(self.faiss_index.ntotal, 50)
        similarities, _ = self.faiss_index.search(all_vectors, k=k)
        
        diversity_scores = similarities.sum(axis=1) - 1.0
        cull_idx_in_storage = np.argmax(diversity_scores)
        cull_unique_id = self.image_storage[cull_idx_in_storage]['id']

        try:
            self.faiss_index.remove_ids(np.array([cull_unique_id]))
        except Exception:
            self._rebuild_faiss_index_after_removal(cull_idx_in_storage)
        
        if cull_unique_id in self.metadata:
            del self.metadata[cull_unique_id]
        
        del self.image_storage[cull_idx_in_storage]
        del self.stored_embeddings[cull_idx_in_storage]
        
        print(f"[Buffer] ğŸ—‘ï¸ Removed redundant sample (ID: {cull_unique_id})")

    def _rebuild_faiss_index_after_removal(self, removed_idx):
        """Faiss ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        print("[Buffer] ğŸ”§ Rebuilding Faiss index...")
        self._initialize_faiss()
        
        for i, (item, embedding) in enumerate(zip(self.image_storage, self.stored_embeddings)):
            if i != removed_idx:
                self.faiss_index.add_with_ids(
                    embedding.reshape(1, -1), 
                    np.array([item['id']])
                )

    def _select_hard_samples(self, num_hard, new_embedding, current_user_id):
        """ì–´ë ¤ìš´ ìƒ˜í”Œ ì„ íƒ"""
        if len(self.stored_embeddings) == 0:
            return []
            
        buffer_embeddings = np.array(self.stored_embeddings)
        new_emb = new_embedding.cpu().numpy().flatten()
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for i, buffer_emb in enumerate(buffer_embeddings):
            similarity = np.dot(new_emb, buffer_emb.flatten()) / (
                np.linalg.norm(new_emb) * np.linalg.norm(buffer_emb.flatten())
            )
            
            is_same_user = self.image_storage[i]['user_id'] == current_user_id
            
            # Hard score ê³„ì‚°
            if is_same_user:
                hard_score = 1.0 - similarity  # ê°™ì€ ìœ ì €ì¸ë° ë©€ë¦¬ ìˆìŒ
            else:
                hard_score = similarity       # ë‹¤ë¥¸ ìœ ì €ì¸ë° ê°€ê¹Œì´ ìˆìŒ
                
            similarities.append({
                'index': i,
                'similarity': similarity,
                'hard_score': hard_score,
                'is_same_user': is_same_user
            })
        
        # Hard score ê¸°ì¤€ ì •ë ¬
        similarities.sort(key=lambda x: x['hard_score'], reverse=True)
        
        # ìƒìœ„ ì–´ë ¤ìš´ ìƒ˜í”Œë“¤ ì„ íƒ
        hard_samples = similarities[:num_hard]
        hard_indices = [item['index'] for item in hard_samples]
        
        # í†µê³„
        hard_positives = sum(1 for item in hard_samples if item['is_same_user'])
        hard_negatives = len(hard_samples) - hard_positives
        
        print(f"[HardMining] ğŸ’ª Selected {num_hard} hard samples:")
        print(f"   Hard positives (same user, far): {hard_positives}")
        print(f"   Hard negatives (diff user, close): {hard_negatives}")
        
        return hard_indices

    def _apply_augmentation(self, image, sample_info=""):
        """3ê°€ì§€ ì¦ê°• ì ìš©"""
        if not self.enable_augmentation:
            return image
            
        result = image.clone()
        applied_augs = []
        
        # 1. ê¸°í•˜í•™ì  ì¦ê°•
        if (self.geometric_transform and 
            getattr(self.aug_config, 'enable_geometric', False) and
            np.random.random() < getattr(self.aug_config, 'geometric_probability', 0.3)):
            
            result = self.geometric_transform(result)
            applied_augs.append("Geometric")
        
        # 2. í•´ìƒë„ ì ì‘ ì¦ê°•
        if (self.resolution_config['enable'] and 
            np.random.random() < self.resolution_config['probability']):
            
            result = self._apply_resolution_augmentation(result)
            applied_augs.append("Resolution")
        
        # 3. ë…¸ì´ì¦ˆ ì¦ê°•
        if (self.noise_config['enable'] and 
            np.random.random() < self.noise_config['probability']):
            
            noise_std = np.random.uniform(*self.noise_config['std_range'])
            noise = torch.randn_like(result) * noise_std
            result = result + noise
            applied_augs.append(f"Noise(Ïƒ={noise_std:.3f})")
        
        if applied_augs:
            print(f"[Augmentation] ğŸ¨ {sample_info}: {', '.join(applied_augs)}")
        
        return result

    def _apply_resolution_augmentation(self, image):
        """í•´ìƒë„ ì ì‘ ì¦ê°• (í¬ê¸°ëŠ” 128x128 ìœ ì§€)"""
        # ì¤‘ê°„ í•´ìƒë„ ì„ íƒ
        intermediate_size = random.choice(self.resolution_config['intermediate_sizes'])
        method1 = random.choice(self.resolution_config['methods'])
        method2 = random.choice(self.resolution_config['methods'])
        
        # PIL ë³€í™˜
        pil_image = transforms.ToPILImage()(image)
        
        # ì¤‘ê°„ í•´ìƒë„ë¡œ ë³€í™˜
        method1_mode = getattr(transforms.InterpolationMode, method1.upper())
        intermediate = transforms.Resize(intermediate_size, interpolation=method1_mode)(pil_image)
        
        # ì›ë˜ í¬ê¸°ë¡œ ë³µì›
        method2_mode = getattr(transforms.InterpolationMode, method2.upper())
        final_image = transforms.Resize((128, 128), interpolation=method2_mode)(intermediate)
        
        return transforms.ToTensor()(final_image)

    def sample_with_replacement(self, batch_size, new_embedding=None, current_user_id=None):
        """ì§€ëŠ¥í˜• ìƒ˜í”Œë§ (Hard Mining + ì¦ê°• í†µí•©)"""
        if len(self.image_storage) == 0:
            return [], []

        print(f"[Sampling] ğŸ¯ Intelligent sampling (batch_size: {batch_size})")
        
        # Hard Mining ì ìš© ì—¬ë¶€
        if (self.enable_hard_mining and new_embedding is not None and 
            current_user_id is not None and len(self.image_storage) >= batch_size):
            
            # Hard/Easy ë¹„ìœ¨ ê³„ì‚°
            num_hard = int(batch_size * self.hard_ratio)
            num_easy = batch_size - num_hard
            
            print(f"[Sampling] ğŸ“Š Hard mining composition:")
            print(f"   Hard samples: {num_hard}/{batch_size} ({self.hard_ratio:.1%})")
            print(f"   Easy samples: {num_easy}/{batch_size}")
            
            # Hard samples ì„ íƒ
            hard_indices = self._select_hard_samples(num_hard, new_embedding, current_user_id)
            
            # Easy samples ì„ íƒ (hard ì œì™¸)
            remaining_indices = [i for i in range(len(self.image_storage)) 
                               if i not in hard_indices]
            
            if len(remaining_indices) >= num_easy:
                easy_indices = np.random.choice(remaining_indices, num_easy, replace=False)
            else:
                easy_indices = np.random.choice(remaining_indices, num_easy, replace=True)
            
            all_indices = list(hard_indices) + list(easy_indices)
            
        else:
            # ê¸°ë³¸ ìƒ˜í”Œë§ (ì¤‘ë³µ ë°©ì§€ ìš°ì„ )
            if len(self.image_storage) >= batch_size:
                all_indices = np.random.choice(
                    len(self.image_storage), size=batch_size, replace=False
                )
                print(f"[Sampling] ğŸ“‹ Non-duplicate sampling")
            else:
                all_indices = np.random.choice(
                    len(self.image_storage), size=batch_size, replace=True
                )
                print(f"[Sampling] ğŸ”„ With replacement (buffer: {len(self.image_storage)} < batch: {batch_size})")

        # ìƒ˜í”Œ ì¶”ì¶œ ë° ì¦ê°•
        images = []
        labels = []
        
        for i, idx in enumerate(all_indices):
            item = self.image_storage[idx]
            base_image = item['image'].clone()
            
            # ì¦ê°• ì ìš©
            augmented_image = self._apply_augmentation(
                base_image, 
                sample_info=f"Sample{i+1}(User{item['user_id']})"
            )
            
            images.append(augmented_image)
            labels.append(item['user_id'])

        # í†µê³„ ì¶œë ¥
        unique_users = len(set(labels))
        user_counts = {}
        for label in labels:
            user_counts[label] = user_counts.get(label, 0) + 1
        
        print(f"[Sampling] ğŸ“Š Final batch composition:")
        print(f"   Unique images: {len(set([id(img) for img in images]))}")
        print(f"   Unique users: {unique_users}")
        print(f"   User distribution: {dict(sorted(user_counts.items()))}")
        
        return images, labels

    def sample(self, batch_size, **kwargs):
        """ê¸°ë³¸ ìƒ˜í”Œë§ ì¸í„°í˜ì´ìŠ¤"""
        return self.sample_with_replacement(batch_size, **kwargs)

    def get_diversity_stats(self):
        """ë²„í¼ ë‹¤ì–‘ì„± í†µê³„"""
        if len(self.image_storage) == 0:
            return {
                'total_samples': 0,
                'unique_users': 0,
                'user_distribution': {},
                'diversity_score': 0.0
            }
        
        user_counts = {}
        for item in self.image_storage:
            user_id = item['user_id']
            user_counts[user_id] = user_counts.get(user_id, 0) + 1
        
        unique_users = len(user_counts)
        diversity_score = unique_users / len(self.image_storage)
        
        return {
            'total_samples': len(self.image_storage),
            'unique_users': unique_users,
            'user_distribution': dict(sorted(user_counts.items())),
            'diversity_score': diversity_score
        }

    def save_state(self):
        """ìƒíƒœ ì €ì¥"""
        if self.faiss_index is None:
            return
            
        data_to_save = {
            'faiss_index_data': faiss.serialize_index(self.faiss_index),
            'metadata': self.metadata,
            'image_storage': self.image_storage,
            'stored_embeddings': self.stored_embeddings
        }
        
        with open(self.state_file, 'wb') as f:
            pickle.dump(data_to_save, f)
        
        diversity_stats = self.get_diversity_stats()
        print(f"[Buffer] ğŸ’¾ Saved {len(self.image_storage)} samples")
        print(f"[Buffer] Diversity: {diversity_stats['unique_users']} users, "
              f"{diversity_stats['diversity_score']:.2f} score")

    def _load_state(self):
        """ìƒíƒœ ë¡œë“œ"""
        if not self.state_file.exists():
            return

        try:
            with open(self.state_file, 'rb') as f:
                saved_data = pickle.load(f)
                
                self.faiss_index = faiss.deserialize_index(saved_data['faiss_index_data'])
                self.metadata = saved_data['metadata']
                self.image_storage = saved_data.get('image_storage', [])
                self.stored_embeddings = saved_data.get('stored_embeddings', [])
                
                diversity_stats = self.get_diversity_stats()
                print(f"[Buffer] âœ… Restored {len(self.image_storage)} samples")
                print(f"[Buffer] Diversity: {diversity_stats['unique_users']} users")
                
        except Exception as e:
            print(f"[Buffer] âŒ Failed to load state: {e}")
            self.faiss_index = None
            self.metadata = {}
            self.image_storage = []
            self.stored_embeddings = []

print("âœ… ReplayBuffer ì™„ì „ ìˆ˜ì • ì™„ë£Œ!")