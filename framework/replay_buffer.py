# framework/replay_buffer.py - ìŠ¤ë§ˆíŠ¸ ë²„í¼ ì €ì¥ ë¡œì§ ì¶”ê°€ (ìˆ˜ì • ë²„ì „)

"""
CoCoNut Intelligent Replay Buffer with Smart Storage Logic

ğŸ”¥ NEW FEATURES:
- ìŠ¤ë§ˆíŠ¸ ì €ì¥ ë¡œì§ (smart_add)
- ê¸ì •ìŒ í™•ë³´ë¥¼ ìœ„í•œ ê°•ì œ ì €ì¥
- í•™ìŠµ ì—¬ë¶€ ê¸°ë°˜ ì €ì¥ ê²°ì •
- ì‚¬ìš©ìë³„ ìƒ˜í”Œ ìˆ˜ ê´€ë¦¬
"""

import os
import pickle
import random
from pathlib import Path
from typing import List, Tuple, Dict, Optional

# ğŸ”¥ Faiss import ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
try:
    import faiss
    import numpy as np
    FAISS_AVAILABLE = True
    print("[Buffer] ğŸš€ Faiss available - Buffer optimization enabled")
except ImportError:
    FAISS_AVAILABLE = False
    print("[Buffer] âš ï¸ Faiss not found - using PyTorch fallback")
    import numpy as np

import torch
import torchvision.transforms as transforms
from PIL import Image

class CoconutReplayBuffer:
    def __init__(self, config, storage_dir: Path, feature_dimension: int = 128):
        """
        ì§€ëŠ¥í˜• ë¦¬í”Œë ˆì´ ë²„í¼ ì´ˆê¸°í™” (ìŠ¤ë§ˆíŠ¸ ì €ì¥ ë¡œì§ í¬í•¨)
        """
        self.config = config
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ë³¸ ì„¤ì •
        self.buffer_size = self.config.max_buffer_size
        self.similarity_threshold = self.config.similarity_threshold
        self.feature_dimension = feature_dimension
        
        # ğŸ”¥ NEW: ìŠ¤ë§ˆíŠ¸ ì €ì¥ì„ ìœ„í•œ ì„¤ì •
        self.min_samples_per_user = getattr(config, 'min_samples_per_user', 2)
        
        # ğŸ”¥ ìƒ˜í”Œë§ ì „ëµ ì„¤ì •
        self.sampling_strategy = getattr(self.config, 'sampling_strategy', 'controlled')
        self.force_positive_pairs = getattr(self.config, 'force_positive_pairs', True)
        self.min_positive_pairs = getattr(self.config, 'min_positive_pairs', 1)
        self.max_positive_ratio = getattr(self.config, 'max_positive_ratio', 0.5)
        
        # Faiss ì¸ë±ìŠ¤ ë° ì €ì¥ì†Œ
        self.image_storage = []
        self.faiss_index = None
        self.stored_embeddings = []
        self.metadata = {}
        self.feature_extractor = None
        
        # ğŸ”¥ GPU/CPU í˜¸í™˜ì„±ì„ ìœ„í•œ device ì¶”ì 
        self.device = 'cpu'  # ê¸°ë³¸ê°’, feature_extractor ì„¤ì •ì‹œ ì—…ë°ì´íŠ¸

        # ë°°ì¹˜ êµ¬ì„± ë¹„ìœ¨ (ë‚˜ì¤‘ì— CoconutSystemì—ì„œ ì„¤ì •)
        self.target_positive_ratio = 0.3  # ê¸°ë³¸ê°’
        self.hard_ratio = 0.3             # ê¸°ë³¸ê°’
        self.enable_hard_mining = False   # ê¸°ë³¸ê°’
        
        # ë°ì´í„° ì¦ê°• ì„¤ì • (ë‚˜ì¤‘ì— ì„¤ì •)
        self.enable_augmentation = False
        self.aug_config = None
        self._setup_augmentation_transforms()
        
        # ìƒíƒœ íŒŒì¼ ê²½ë¡œ
        self.state_file = self.storage_dir / 'buffer_state.pkl'
        self._load_state()

        print(f"[Buffer] ğŸ¥¥ CoCoNut Smart Replay Buffer initialized")
        print(f"[Buffer] Strategy: {self.sampling_strategy}")
        print(f"[Buffer] Max buffer size: {self.buffer_size}")
        print(f"[Buffer] Min samples per user: {self.min_samples_per_user}")
        print(f"[Buffer] Current size: {len(self.image_storage)}")

    def smart_add(self, image: torch.Tensor, user_id: int, learned: bool = False):
        """
        ğŸ”¥ NEW: ìŠ¤ë§ˆíŠ¸ ë²„í¼ ì €ì¥ - í•™ìŠµ ì—¬ë¶€ë¥¼ ê³ ë ¤í•œ ì €ì¥ ê²°ì •
        
        Args:
            image: ì €ì¥í•  ì´ë¯¸ì§€
            user_id: ì‚¬ìš©ì ID
            learned: ì´ ìƒ˜í”Œì´ í•™ìŠµì— ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
            
        Returns:
            str: ì €ì¥ ê²°ì • ì´ìœ 
        """
        
        existing_user_samples = [item for item in self.image_storage 
                               if item['user_id'] == user_id]
        
        # Case 1: ì™„ì „ ìƒˆë¡œìš´ ì‚¬ìš©ì - ë¬´ì¡°ê±´ ì €ì¥
        if len(existing_user_samples) == 0:
            reason = "new_user_first_sample"
            self._force_store(image, user_id, reason)
            return reason
        
        # Case 2: ê¸°ì¡´ ì‚¬ìš©ì, ìƒ˜í”Œ ë¶€ì¡± - ê¸ì •ìŒ ìœ„í•´ ì €ì¥
        if len(existing_user_samples) < self.min_samples_per_user:
            reason = "ensuring_positive_pairs"
            self._force_store(image, user_id, reason)
            return reason
        
        # Case 3: ì¶©ë¶„í•œ ìƒ˜í”Œ ë³´ìœ  - ë‹¤ì–‘ì„± ê¸°ë°˜ íŒë‹¨
        if learned:
            # ì´ë¯¸ í•™ìŠµì— í™œìš©í–ˆìœ¼ë¯€ë¡œ ì—„ê²©í•œ ë‹¤ì–‘ì„± ê¸°ì¤€ ì ìš©
            try:
                max_similarity = self._compute_max_similarity_for_user(image, user_id)
                if max_similarity < self.similarity_threshold:
                    reason = "diversity_based_storage_after_learning"
                    self._force_store(image, user_id, reason)
                    return reason
                else:
                    reason = f"too_similar_after_learning_{max_similarity:.3f}"
                    return reason
            except Exception as e:
                print(f"[Buffer] âš ï¸ Similarity computation failed: {e}")
                reason = "diversity_check_failed_store_anyway"
                self._force_store(image, user_id, reason)
                return reason
        else:
            # í•™ìŠµ ì•ˆí–ˆìœ¼ë©´ ì €ì¥í•´ì„œ ë‚˜ì¤‘ì— í™œìš© ê¸°íšŒ ì œê³µ
            reason = "not_learned_store_for_future"
            self._force_store(image, user_id, reason)
            return reason

    def _force_store(self, image: torch.Tensor, user_id: int, reason: str):
        """ğŸ”¥ NEW: ê°•ì œ ì €ì¥ (ë²„í¼ ê³µê°„ í™•ë³´ í›„ ì €ì¥)"""
        # ë²„í¼ê°€ ê°€ë“ ì°¬ ê²½ìš° ê³µê°„ í™•ë³´
        if len(self.image_storage) >= self.buffer_size:
            self._smart_cull_for_positive_pairs()

        unique_id = len(self.image_storage)
        self.image_storage.append({
            'image': image.cpu().clone(),
            'user_id': user_id,
            'id': unique_id,
            'storage_reason': reason
        })
        
        # ì„ë² ë”©ë„ ì €ì¥ (ê¸°ì¡´ ë°©ì‹)
        if hasattr(self, 'stored_embeddings'):
            try:
                with torch.no_grad():
                    embedding = self._extract_feature_for_diversity(image.to(self.device))
                    embedding_np = embedding.cpu().numpy().astype('float32')
                    self.stored_embeddings.append(embedding_np.copy())
                    
                    # Faiss ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
                    if FAISS_AVAILABLE and self.faiss_index is not None:
                        faiss.normalize_L2(embedding_np)
                        self.faiss_index.add_with_ids(embedding_np.reshape(1, -1), np.array([unique_id]))
                        
            except Exception as e:
                print(f"[Buffer] âš ï¸ Embedding extraction failed: {e}")
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if hasattr(self, 'metadata'):
            self.metadata[unique_id] = {'user_id': user_id, 'reason': reason}

        print(f"[Buffer] âœ… Force stored sample (ID: {unique_id}, User: {user_id}, Reason: {reason})")

    def _compute_max_similarity_for_user(self, image: torch.Tensor, user_id: int):
        """ğŸ”¥ NEW: íŠ¹ì • ì‚¬ìš©ìì˜ ìƒ˜í”Œë“¤ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„ ê³„ì‚°"""
        user_samples = [item for item in self.image_storage if item['user_id'] == user_id]
        
        if len(user_samples) == 0:
            return 0.0
        
        # ìƒˆë¡œìš´ ì´ë¯¸ì§€ì˜ íŠ¹ì§• ì¶”ì¶œ
        with torch.no_grad():
            new_embedding = self._extract_feature_for_diversity(image.to(self.device))
            new_embedding_np = new_embedding.cpu().numpy().flatten()
        
        max_sim = 0.0
        for sample in user_samples:
            try:
                # ê¸°ì¡´ ìƒ˜í”Œì˜ íŠ¹ì§• ì¶”ì¶œ
                stored_image = sample['image'].to(self.device)
                with torch.no_grad():
                    stored_embedding = self._extract_feature_for_diversity(stored_image)
                    stored_embedding_np = stored_embedding.cpu().numpy().flatten()
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = np.dot(new_embedding_np, stored_embedding_np) / (
                    np.linalg.norm(new_embedding_np) * np.linalg.norm(stored_embedding_np) + 1e-8
                )
                max_sim = max(max_sim, similarity)
            except Exception as e:
                print(f"[Buffer] âš ï¸ Similarity calculation failed for sample: {e}")
                continue
        
        return max_sim

    def _smart_cull_for_positive_pairs(self):
        """ğŸ”¥ NEW: ê¸ì •ìŒì„ ë³´ì¡´í•˜ë©´ì„œ ì§€ëŠ¥ì  íë ˆì´ì…˜"""
        print(f"[Buffer] ğŸ”„ Smart culling to preserve positive pairs...")
        
        # 1. ì‚¬ìš©ìë³„ ìƒ˜í”Œ ìˆ˜ ë¶„ì„
        user_counts = {}
        for item in self.image_storage:
            user_id = item['user_id']
            user_counts[user_id] = user_counts.get(user_id, 0) + 1
        
        # 2. ìƒ˜í”Œì´ ë§ì€ ì‚¬ìš©ìë¶€í„° ì œê±° ëŒ€ìƒ ì„ ì •
        over_sampled_users = [uid for uid, count in user_counts.items() 
                             if count > self.min_samples_per_user]
        
        if over_sampled_users:
            # ê°€ì¥ ë§ì€ ìƒ˜í”Œì„ ê°€ì§„ ì‚¬ìš©ìì˜ ê°€ì¥ ìœ ì‚¬í•œ ìƒ˜í”Œ ì œê±°
            victim_user = max(over_sampled_users, key=lambda uid: user_counts[uid])
            victim_sample_idx = self._find_most_similar_sample_for_user(victim_user)
            
            if victim_sample_idx is not None:
                victim_id = self.image_storage[victim_sample_idx]['id']
                
                # ì œê±° ì‹¤í–‰
                del self.image_storage[victim_sample_idx]
                if victim_sample_idx < len(self.stored_embeddings):
                    del self.stored_embeddings[victim_sample_idx]
                if victim_id in self.metadata:
                    del self.metadata[victim_id]
                
                print(f"[Buffer] ğŸ—‘ï¸ Removed redundant sample (User: {victim_user}, ID: {victim_id})")
            else:
                # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
                self._cull()
        else:
            # ëª¨ë“  ì‚¬ìš©ìê°€ ìµœì†Œ ìƒ˜í”Œ ì´í•˜ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            self._cull()

    def _find_most_similar_sample_for_user(self, user_id: int):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ê°€ì¥ ìœ ì‚¬í•œ ìƒ˜í”Œ ì°¾ê¸°"""
        user_samples = [(i, item) for i, item in enumerate(self.image_storage) 
                       if item['user_id'] == user_id]
        
        if len(user_samples) < 2:
            return None
        
        max_similarity = -1
        most_similar_idx = None
        
        for i, (idx1, sample1) in enumerate(user_samples):
            for j, (idx2, sample2) in enumerate(user_samples[i+1:], i+1):
                try:
                    # ë‘ ìƒ˜í”Œ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
                    img1 = sample1['image'].to(self.device)
                    img2 = sample2['image'].to(self.device)
                    
                    with torch.no_grad():
                        emb1 = self._extract_feature_for_diversity(img1).cpu().numpy().flatten()
                        emb2 = self._extract_feature_for_diversity(img2).cpu().numpy().flatten()
                    
                    similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-8)
                    
                    if similarity > max_similarity:
                        max_similarity = similarity
                        # ë” ìµœê·¼ ìƒ˜í”Œì„ ì œê±° (ì¸ë±ìŠ¤ê°€ í° ê²ƒ)
                        most_similar_idx = max(idx1, idx2)
                        
                except Exception as e:
                    print(f"[Buffer] âš ï¸ Similarity calculation failed: {e}")
                    continue
        
        return most_similar_idx

    def update_batch_composition_config(self, target_positive_ratio: float, hard_mining_ratio: float):
        """ë°°ì¹˜ êµ¬ì„± ë¹„ìœ¨ ì—…ë°ì´íŠ¸ (CoconutSystemì—ì„œ í˜¸ì¶œ)"""
        self.target_positive_ratio = target_positive_ratio
        self.hard_ratio = hard_mining_ratio
        print(f"[Buffer] ğŸ¯ Batch composition config updated:")
        print(f"   Target positive ratio: {self.target_positive_ratio:.1%}")
        print(f"   Hard mining ratio: {self.hard_ratio:.1%}")

    def update_hard_mining_config(self, enable_hard_mining: bool, hard_ratio: float):
        """Hard Mining ì„¤ì • ì—…ë°ì´íŠ¸"""
        self.enable_hard_mining = enable_hard_mining
        self.hard_ratio = hard_ratio
        print(f"[Buffer] ğŸ”¥ Hard Mining updated: {self.enable_hard_mining} (ratio: {self.hard_ratio:.1%})")

    def update_augmentation_config(self, enable_augmentation: bool, aug_config):
        """ë°ì´í„° ì¦ê°• ì„¤ì • ì—…ë°ì´íŠ¸"""
        self.enable_augmentation = enable_augmentation
        self.aug_config = aug_config
        self._setup_augmentation_transforms()
        print(f"[Buffer] ğŸ¨ Augmentation updated: {self.enable_augmentation}")

    def set_feature_extractor(self, model):
        """íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•œ ëª¨ë¸ ì„¤ì •"""
        self.feature_extractor = model
        # ğŸ”¥ ëª¨ë¸ì˜ device ì¶”ì 
        if model is not None:
            self.device = next(model.parameters()).device
            print(f"[Buffer] ğŸ”§ Feature extractor device: {self.device}")

    def _initialize_faiss(self):
        """Faiss ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        if FAISS_AVAILABLE:
            index = faiss.IndexFlatIP(self.feature_dimension)
            self.faiss_index = faiss.IndexIDMap(index)
            print(f"[Buffer] Faiss index initialized with dimension {self.feature_dimension}")
        else:
            self.faiss_index = None
            print(f"[Buffer] Faiss not available - using PyTorch fallback")

    def _extract_feature_for_diversity(self, image):
        """ë‹¤ì–‘ì„± ì¸¡ì •ì„ ìœ„í•œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ (GPU í˜¸í™˜ì„± ë³´ì¥)"""
        if self.feature_extractor is None:
            raise ValueError("Feature extractor not set")
        
        # ğŸ”¥ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ê³¼ ê°™ì€ deviceë¡œ ê°•ì œ ì´ë™
        image = image.to(self.device)
        
        if len(image.shape) == 3:
            image = image.unsqueeze(0)
        
        with torch.no_grad():
            # getFeatureCode ë©”ì„œë“œ ì‚¬ìš© (128ì°¨ì› ë°˜í™˜)
            features = self.feature_extractor.getFeatureCode(image)
        
        return features

    def add(self, image: torch.Tensor, user_id: int):
        """ìƒˆë¡œìš´ ê²½í—˜ì„ ë²„í¼ì— ì¶”ê°€ (ê¸°ì¡´ ë°©ì‹ - í˜¸í™˜ì„± ìœ ì§€)"""
        
        with torch.no_grad():
            # ğŸ”¥ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ deviceë¡œ ê°•ì œ ì´ë™
            image_for_extraction = image.to(self.device)
            
            embedding = self._extract_feature_for_diversity(image_for_extraction)
            embedding_np = embedding.cpu().numpy().astype('float32')
            
            # Faiss ì •ê·œí™” (CPUì—ì„œ ìˆ˜í–‰)
            if FAISS_AVAILABLE:
                faiss.normalize_L2(embedding_np)

        if self.faiss_index is None:
            self._initialize_faiss()

        # ë‹¤ì–‘ì„± í™•ì¸
        if self.faiss_index is None or (FAISS_AVAILABLE and self.faiss_index.ntotal == 0):
            max_similarity = 0.0
        elif FAISS_AVAILABLE:
            distances, _ = self.faiss_index.search(embedding_np, k=1)
            max_similarity = distances[0][0]
        else:
            # Faiss ì—†ì„ ë•Œ PyTorch ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
            max_similarity = self._compute_pytorch_similarity(embedding_np)

        # ìƒˆë¡œìš´ ê²½í—˜ì´ë©´ ì €ì¥
        if max_similarity < self.similarity_threshold:
            if len(self.image_storage) >= self.buffer_size:
                self._cull()
            
            unique_id = len(self.image_storage)
            self.image_storage.append({
                'image': image.cpu().clone(),  # ğŸ”¥ í•­ìƒ CPUì— ì €ì¥
                'user_id': user_id,
                'id': unique_id
            })
            
            self.stored_embeddings.append(embedding_np.copy())
            if FAISS_AVAILABLE and self.faiss_index is not None:
                self.faiss_index.add_with_ids(embedding_np, np.array([unique_id]))
            self.metadata[unique_id] = {'user_id': user_id}
            
            print(f"[Buffer] âœ… Added diverse sample (ID: {unique_id}, User: {user_id}). "
                  f"Buffer: {len(self.image_storage)}/{self.buffer_size}")
        else:
            print(f"[Buffer] âš ï¸ Similar sample skipped (similarity: {max_similarity:.4f} >= {self.similarity_threshold})")

    def _compute_pytorch_similarity(self, new_embedding):
        """Faiss ì—†ì„ ë•Œ PyTorchë¡œ ìœ ì‚¬ë„ ê³„ì‚°"""
        if len(self.stored_embeddings) == 0:
            return 0.0
        
        new_emb = torch.tensor(new_embedding).flatten()
        max_sim = 0.0
        
        for stored_emb in self.stored_embeddings:
            stored_tensor = torch.tensor(stored_emb).flatten()
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = torch.cosine_similarity(new_emb.unsqueeze(0), stored_tensor.unsqueeze(0)).item()
            max_sim = max(max_sim, similarity)
        
        return max_sim

    def _cull(self):
        """ê°€ì¥ ì¤‘ë³µë˜ëŠ” ë°ì´í„° ì œê±° (ê¸°ì¡´ ë°©ì‹)"""
        if len(self.stored_embeddings) < 2:
            return

        print(f"[Buffer] ğŸ”„ Buffer full. Finding most redundant sample...")
        
        if FAISS_AVAILABLE and self.faiss_index is not None and self.faiss_index.ntotal >= 2:
            all_vectors = np.vstack(self.stored_embeddings)
            k = min(self.faiss_index.ntotal, 50)
            similarities, _ = self.faiss_index.search(all_vectors, k=k)
            diversity_scores = similarities.sum(axis=1) - 1.0
            cull_idx_in_storage = np.argmax(diversity_scores)
        else:
            # PyTorch ê¸°ë°˜ ë‹¤ì–‘ì„± ê³„ì‚°
            cull_idx_in_storage = self._find_most_redundant_pytorch()
        
        cull_unique_id = self.image_storage[cull_idx_in_storage]['id']

        # Faiss ì¸ë±ìŠ¤ì—ì„œ ì œê±°
        if FAISS_AVAILABLE and self.faiss_index is not None:
            try:
                self.faiss_index.remove_ids(np.array([cull_unique_id]))
            except Exception:
                self._rebuild_faiss_index_after_removal(cull_idx_in_storage)
        
        # ë©”íƒ€ë°ì´í„° ì •ë¦¬
        if cull_unique_id in self.metadata:
            del self.metadata[cull_unique_id]
        
        del self.image_storage[cull_idx_in_storage]
        del self.stored_embeddings[cull_idx_in_storage]
        
        print(f"[Buffer] ğŸ—‘ï¸ Removed redundant sample (ID: {cull_unique_id})")

    def _find_most_redundant_pytorch(self):
        """PyTorchë¡œ ê°€ì¥ ì¤‘ë³µë˜ëŠ” ìƒ˜í”Œ ì°¾ê¸°"""
        max_similarity = -1
        most_redundant_idx = 0
        
        for i, emb1 in enumerate(self.stored_embeddings):
            total_similarity = 0
            tensor1 = torch.tensor(emb1).flatten()
            
            for j, emb2 in enumerate(self.stored_embeddings):
                if i != j:
                    tensor2 = torch.tensor(emb2).flatten()
                    sim = torch.cosine_similarity(tensor1.unsqueeze(0), tensor2.unsqueeze(0)).item()
                    total_similarity += sim
            
            if total_similarity > max_similarity:
                max_similarity = total_similarity
                most_redundant_idx = i
        
        return most_redundant_idx

    def _rebuild_faiss_index_after_removal(self, removed_idx):
        """Faiss ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        if not FAISS_AVAILABLE:
            return
            
        print("[Buffer] ğŸ”§ Rebuilding Faiss index...")
        self._initialize_faiss()
        
        for i, (item, embedding) in enumerate(zip(self.image_storage, self.stored_embeddings)):
            if i != removed_idx and self.faiss_index is not None:
                self.faiss_index.add_with_ids(
                    embedding.reshape(1, -1), 
                    np.array([item['id']])
                )

    def sample_with_controlled_composition(self, batch_size: int, new_embedding: torch.Tensor = None, 
                                         current_user_id: int = None) -> Tuple[List, List]:
        """
        ì œì–´ëœ ë°°ì¹˜ êµ¬ì„±ìœ¼ë¡œ ì •í™•í•œ ë¹„ìœ¨ ìƒ˜í”Œë§ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
        """
        print(f"ğŸ¯ [Controlled] Creating controlled batch (size: {batch_size})")
        print(f"   Target positive ratio: {self.target_positive_ratio:.1%}")
        print(f"   Hard mining ratio: {self.hard_ratio:.1%}")
        
        if len(self.image_storage) == 0:
            return [], []

        # 1. ğŸ¯ ë°°ì¹˜ êµ¬ì„± ê³„íš ìˆ˜ë¦½
        target_positive_samples = max(2, int(batch_size * self.target_positive_ratio))
        if target_positive_samples % 2 == 1:
            target_positive_samples += 1
        target_positive_pairs = target_positive_samples // 2
        
        target_hard_samples = int(batch_size * self.hard_ratio)
        remaining_regular = batch_size - target_positive_samples - target_hard_samples
        
        if remaining_regular < 0:
            print(f"[Controlled] âš ï¸ Batch size too small, adjusting targets...")
            target_hard_samples = max(0, batch_size - target_positive_samples)
            remaining_regular = batch_size - target_positive_samples - target_hard_samples
        
        print(f"ğŸ“‹ [Controlled] Planned composition:")
        print(f"   Positive pairs: {target_positive_pairs} pairs ({target_positive_samples} samples)")
        print(f"   Hard samples: {target_hard_samples} samples")
        print(f"   Regular samples: {remaining_regular} samples")

        selected_indices = []
        selected_labels = []
        use