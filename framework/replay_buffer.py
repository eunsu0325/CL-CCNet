# framework/replay_buffer.py - learned íŒŒë¼ë¯¸í„° ì œê±°í•œ ë‹¨ìˆœí™” ë²„ì „

"""
CoCoNut Intelligent Replay Buffer with Simplified Smart Storage Logic

ğŸ”¥ SIMPLIFIED FEATURES:
- ì²« ìƒ˜í”Œë§Œ ë¬´ì¡°ê±´ ì €ì¥, ë‚˜ë¨¸ì§€ëŠ” ë‹¤ì–‘ì„± ê¸°ë°˜
- learned íŒŒë¼ë¯¸í„° ì œê±°ë¡œ ë‹¨ìˆœí™”
- ì œì–´ëœ ë°°ì¹˜ êµ¬ì„± (positive/hard/regular ë¹„ìœ¨)
- Faiss ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° ë° ë‹¤ì–‘ì„± í™•ë³´
- í•˜ë“œ ë§ˆì´ë‹ ì§€ì›
"""

import os
import pickle
import random
from pathlib import Path
from typing import List, Tuple, Dict, Optional

# ğŸ”¥ Faiss import ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
try:
    import faiss
    import numpy as np
    FAISS_AVAILABLE = True
    print("[Buffer] ğŸš€ Faiss available - Buffer optimization enabled")
except ImportError:
    FAISS_AVAILABLE = False
    print("[Buffer] âš ï¸ Faiss not found - using PyTorch fallback")
    import numpy as np

import torch
import torchvision.transforms as transforms
from PIL import Image

class CoconutReplayBuffer:
    def __init__(self, config, storage_dir: Path, feature_dimension: int = 128):
        """
        ì§€ëŠ¥í˜• ë¦¬í”Œë ˆì´ ë²„í¼ ì´ˆê¸°í™” (ë‹¨ìˆœí™”ëœ ìŠ¤ë§ˆíŠ¸ ì €ì¥ ë¡œì§)
        """
        self.config = config
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ë³¸ ì„¤ì •
        self.buffer_size = self.config.max_buffer_size
        self.similarity_threshold = self.config.similarity_threshold
        self.feature_dimension = feature_dimension
        
        # ğŸ”¥ ìƒ˜í”Œë§ ì „ëµ ì„¤ì •
        self.sampling_strategy = getattr(self.config, 'sampling_strategy', 'controlled')
        self.force_positive_pairs = getattr(self.config, 'force_positive_pairs', True)
        self.min_positive_pairs = getattr(self.config, 'min_positive_pairs', 1)
        self.max_positive_ratio = getattr(self.config, 'max_positive_ratio', 0.5)
        
        # Faiss ì¸ë±ìŠ¤ ë° ì €ì¥ì†Œ
        self.image_storage = []
        self.faiss_index = None
        self.stored_embeddings = []
        self.metadata = {}
        self.feature_extractor = None
        
        # ğŸ”¥ GPU/CPU í˜¸í™˜ì„±ì„ ìœ„í•œ device ì¶”ì 
        self.device = 'cpu'  # ê¸°ë³¸ê°’, feature_extractor ì„¤ì •ì‹œ ì—…ë°ì´íŠ¸

        # ë°°ì¹˜ êµ¬ì„± ë¹„ìœ¨ (ë‚˜ì¤‘ì— CoconutSystemì—ì„œ ì„¤ì •)
        self.target_positive_ratio = 0.3  # ê¸°ë³¸ê°’
        self.hard_ratio = 0.3             # ê¸°ë³¸ê°’
        self.enable_hard_mining = False   # ê¸°ë³¸ê°’
        
        # ë°ì´í„° ì¦ê°• ì„¤ì • (ë‚˜ì¤‘ì— ì„¤ì •)
        self.enable_augmentation = False
        self.aug_config = None
        self._setup_augmentation_transforms()
        
        # ìƒíƒœ íŒŒì¼ ê²½ë¡œ
        self.state_file = self.storage_dir / 'buffer_state.pkl'
        self._load_state()

        print(f"[Buffer] ğŸ¥¥ CoCoNut Simplified Replay Buffer initialized")
        print(f"[Buffer] Strategy: {self.sampling_strategy}")
        print(f"[Buffer] Max buffer size: {self.buffer_size}")
        print(f"[Buffer] Similarity threshold: {self.similarity_threshold}")
        print(f"[Buffer] Current size: {len(self.image_storage)}")

    def smart_add(self, image: torch.Tensor, user_id: int):
        """
        ğŸ”¥ SIMPLIFIED: ë‹¨ìˆœí•˜ê³  ëª…í™•í•œ ìŠ¤ë§ˆíŠ¸ ë²„í¼ ì €ì¥
        
        ë‹¨ìˆœí•œ ë¡œì§:
        - ì²« ë²ˆì§¸ ìƒ˜í”Œë§Œ ë¬´ì¡°ê±´ ì €ì¥ (ê¸ì •ìŒ í•™ìŠµ ê¸°ë°˜ ë§ˆë ¨)
        - ë‘ ë²ˆì§¸ ìƒ˜í”Œë¶€í„°ëŠ” í•­ìƒ ë‹¤ì–‘ì„± ê¸°ë°˜ íŒë‹¨
        
        Args:
            image: ì €ì¥í•  ì´ë¯¸ì§€
            user_id: ì‚¬ìš©ì ID
            
        Returns:
            str: ì €ì¥ ê²°ì • ì´ìœ 
        """
        
        existing_user_samples = [item for item in self.image_storage 
                               if item['user_id'] == user_id]
        
        # Case 1: ì™„ì „ ìƒˆë¡œìš´ ì‚¬ìš©ì - ì²« ìƒ˜í”Œë§Œ ë¬´ì¡°ê±´ ì €ì¥
        if len(existing_user_samples) == 0:
            reason = "new_user_first_sample"
            self._force_store(image, user_id, reason)
            print(f"[Buffer] ğŸ†• New user {user_id}: storing first sample unconditionally")
            return reason
        
        # Case 2: ê¸°ì¡´ ì‚¬ìš©ì - í•­ìƒ ë‹¤ì–‘ì„± ê¸°ë°˜ íŒë‹¨
        print(f"[Buffer] ğŸ‘¤ Existing user {user_id}: applying diversity-based decision")
        print(f"[Buffer] ğŸ“Š User has {len(existing_user_samples)} samples in buffer")
        
        try:
            max_similarity = self._compute_max_similarity_for_user(image, user_id)
            print(f"[Buffer] ğŸ” Max similarity with user's samples: {max_similarity:.4f}")
            
            # ë‹¨ìˆœí•œ ì„ê³„ê°’ ì ìš©
            threshold = self.similarity_threshold  # ê¸°ë³¸ ì„ê³„ê°’ (ì˜ˆ: 0.85)
            
            print(f"[Buffer] ğŸ¯ Applied threshold: {threshold:.3f}")
            
            if max_similarity < threshold:
                reason = "diversity_sufficient"
                self._force_store(image, user_id, reason)
                print(f"[Buffer] âœ… Stored: diversity sufficient ({max_similarity:.3f} < {threshold:.3f})")
                return reason
            else:
                reason = f"too_similar_{max_similarity:.3f}"
                print(f"[Buffer] âŒ Skipped: too similar ({max_similarity:.3f} >= {threshold:.3f})")
                return reason
                
        except Exception as e:
            print(f"[Buffer] âš ï¸ Similarity computation failed: {e}")
            # ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ ì €ì¥ (ì•ˆì „ì¥ì¹˜)
            reason = "similarity_check_failed_store_anyway"
            self._force_store(image, user_id, reason)
            return reason

    def _force_store(self, image: torch.Tensor, user_id: int, reason: str):
        """ğŸ”¥ ê°•ì œ ì €ì¥ (ë²„í¼ ê³µê°„ í™•ë³´ í›„ ì €ì¥)"""
        # ë²„í¼ê°€ ê°€ë“ ì°¬ ê²½ìš° ê³µê°„ í™•ë³´
        if len(self.image_storage) >= self.buffer_size:
            self._smart_cull_for_positive_pairs()

        unique_id = len(self.image_storage)
        self.image_storage.append({
            'image': image.cpu().clone(),
            'user_id': user_id,
            'id': unique_id,
            'storage_reason': reason
        })
        
        # ì„ë² ë”©ë„ ì €ì¥
        if hasattr(self, 'stored_embeddings'):
            try:
                with torch.no_grad():
                    embedding = self._extract_feature_for_diversity(image.to(self.device))
                    embedding_np = embedding.cpu().numpy().astype('float32')
                    self.stored_embeddings.append(embedding_np.copy())
                    
                    # Faiss ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
                    if FAISS_AVAILABLE and self.faiss_index is not None:
                        faiss.normalize_L2(embedding_np)
                        self.faiss_index.add_with_ids(embedding_np.reshape(1, -1), np.array([unique_id]))
                        
            except Exception as e:
                print(f"[Buffer] âš ï¸ Embedding extraction failed: {e}")
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if hasattr(self, 'metadata'):
            self.metadata[unique_id] = {'user_id': user_id, 'reason': reason}

        print(f"[Buffer] âœ… Force stored sample (ID: {unique_id}, User: {user_id}, Reason: {reason})")

    def _compute_max_similarity_for_user(self, image: torch.Tensor, user_id: int):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ìƒ˜í”Œë“¤ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„ ê³„ì‚°"""
        user_samples = [item for item in self.image_storage if item['user_id'] == user_id]
        
        if len(user_samples) == 0:
            return 0.0
        
        # ìƒˆë¡œìš´ ì´ë¯¸ì§€ì˜ íŠ¹ì§• ì¶”ì¶œ
        with torch.no_grad():
            new_embedding = self._extract_feature_for_diversity(image.to(self.device))
            new_embedding_np = new_embedding.cpu().numpy().flatten()
        
        max_sim = 0.0
        for sample in user_samples:
            try:
                # ê¸°ì¡´ ìƒ˜í”Œì˜ íŠ¹ì§• ì¶”ì¶œ
                stored_image = sample['image'].to(self.device)
                with torch.no_grad():
                    stored_embedding = self._extract_feature_for_diversity(stored_image)
                    stored_embedding_np = stored_embedding.cpu().numpy().flatten()
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = np.dot(new_embedding_np, stored_embedding_np) / (
                    np.linalg.norm(new_embedding_np) * np.linalg.norm(stored_embedding_np) + 1e-8
                )
                max_sim = max(max_sim, similarity)
            except Exception as e:
                print(f"[Buffer] âš ï¸ Similarity calculation failed for sample: {e}")
                continue
        
        return max_sim

    def _smart_cull_for_positive_pairs(self):
        """ê¸ì •ìŒì„ ë³´ì¡´í•˜ë©´ì„œ ì§€ëŠ¥ì  íë ˆì´ì…˜"""
        print(f"[Buffer] ğŸ”„ Smart culling to preserve positive pairs...")
        
        # 1. ì‚¬ìš©ìë³„ ìƒ˜í”Œ ìˆ˜ ë¶„ì„
        user_counts = {}
        for item in self.image_storage:
            user_id = item['user_id']
            user_counts[user_id] = user_counts.get(user_id, 0) + 1
        
        # 2. ìƒ˜í”Œì´ 2ê°œ ì´ìƒì¸ ì‚¬ìš©ìë¶€í„° ì œê±° ëŒ€ìƒ ì„ ì •
        over_sampled_users = [uid for uid, count in user_counts.items() if count >= 2]
        
        if over_sampled_users:
            # ê°€ì¥ ë§ì€ ìƒ˜í”Œì„ ê°€ì§„ ì‚¬ìš©ìì˜ ê°€ì¥ ìœ ì‚¬í•œ ìƒ˜í”Œ ì œê±°
            victim_user = max(over_sampled_users, key=lambda uid: user_counts[uid])
            victim_sample_idx = self._find_most_similar_sample_for_user(victim_user)
            
            if victim_sample_idx is not None:
                victim_id = self.image_storage[victim_sample_idx]['id']
                
                # ì œê±° ì‹¤í–‰
                del self.image_storage[victim_sample_idx]
                if victim_sample_idx < len(self.stored_embeddings):
                    del self.stored_embeddings[victim_sample_idx]
                if victim_id in self.metadata:
                    del self.metadata[victim_id]
                
                print(f"[Buffer] ğŸ—‘ï¸ Removed redundant sample (User: {victim_user}, ID: {victim_id})")
            else:
                # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
                self._cull()
        else:
            # ëª¨ë“  ì‚¬ìš©ìê°€ 1ê°œì”©ë§Œ ê°€ì§€ê³  ìˆìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            self._cull()

    def _find_most_similar_sample_for_user(self, user_id: int):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ê°€ì¥ ìœ ì‚¬í•œ ìƒ˜í”Œ ì°¾ê¸°"""
        user_samples = [(i, item) for i, item in enumerate(self.image_storage) 
                       if item['user_id'] == user_id]
        
        if len(user_samples) < 2:
            return None
        
        max_similarity = -1
        most_similar_idx = None
        
        for i, (idx1, sample1) in enumerate(user_samples):
            for j, (idx2, sample2) in enumerate(user_samples[i+1:], i+1):
                try:
                    # ë‘ ìƒ˜í”Œ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
                    img1 = sample1['image'].to(self.device)
                    img2 = sample2['image'].to(self.device)
                    
                    with torch.no_grad():
                        emb1 = self._extract_feature_for_diversity(img1).cpu().numpy().flatten()
                        emb2 = self._extract_feature_for_diversity(img2).cpu().numpy().flatten()
                    
                    similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-8)
                    
                    if similarity > max_similarity:
                        max_similarity = similarity
                        # ë” ìµœê·¼ ìƒ˜í”Œì„ ì œê±° (ì¸ë±ìŠ¤ê°€ í° ê²ƒ)
                        most_similar_idx = max(idx1, idx2)
                        
                except Exception as e:
                    print(f"[Buffer] âš ï¸ Similarity calculation failed: {e}")
                    continue
        
        return most_similar_idx

    def update_batch_composition_config(self, target_positive_ratio: float, hard_mining_ratio: float):
        """ë°°ì¹˜ êµ¬ì„± ë¹„ìœ¨ ì—…ë°ì´íŠ¸ (CoconutSystemì—ì„œ í˜¸ì¶œ)"""
        self.target_positive_ratio = target_positive_ratio
        self.hard_ratio = hard_mining_ratio
        print(f"[Buffer] ğŸ¯ Batch composition config updated:")
        print(f"   Target positive ratio: {self.target_positive_ratio:.1%}")
        print(f"   Hard mining ratio: {self.hard_ratio:.1%}")

    def update_hard_mining_config(self, enable_hard_mining: bool, hard_ratio: float):
        """Hard Mining ì„¤ì • ì—…ë°ì´íŠ¸"""
        self.enable_hard_mining = enable_hard_mining
        self.hard_ratio = hard_ratio
        print(f"[Buffer] ğŸ”¥ Hard Mining updated: {self.enable_hard_mining} (ratio: {self.hard_ratio:.1%})")

    def update_augmentation_config(self, enable_augmentation: bool, aug_config):
        """ë°ì´í„° ì¦ê°• ì„¤ì • ì—…ë°ì´íŠ¸"""
        self.enable_augmentation = enable_augmentation
        self.aug_config = aug_config
        self._setup_augmentation_transforms()
        print(f"[Buffer] ğŸ¨ Augmentation updated: {self.enable_augmentation}")

    def set_feature_extractor(self, model):
        """íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•œ ëª¨ë¸ ì„¤ì •"""
        self.feature_extractor = model
        # ğŸ”¥ ëª¨ë¸ì˜ device ì¶”ì 
        if model is not None:
            self.device = next(model.parameters()).device
            print(f"[Buffer] ğŸ”§ Feature extractor device: {self.device}")

    def _initialize_faiss(self):
        """Faiss ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        if FAISS_AVAILABLE:
            index = faiss.IndexFlatIP(self.feature_dimension)
            self.faiss_index = faiss.IndexIDMap(index)
            print(f"[Buffer] Faiss index initialized with dimension {self.feature_dimension}")
        else:
            self.faiss_index = None
            print(f"[Buffer] Faiss not available - using PyTorch fallback")

    def _extract_feature_for_diversity(self, image):
        """ë‹¤ì–‘ì„± ì¸¡ì •ì„ ìœ„í•œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ (GPU í˜¸í™˜ì„± ë³´ì¥)"""
        if self.feature_extractor is None:
            raise ValueError("Feature extractor not set")
        
        # ğŸ”¥ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ê³¼ ê°™ì€ deviceë¡œ ê°•ì œ ì´ë™
        image = image.to(self.device)
        
        if len(image.shape) == 3:
            image = image.unsqueeze(0)
        
        with torch.no_grad():
            # getFeatureCode ë©”ì„œë“œ ì‚¬ìš© (128ì°¨ì› ë°˜í™˜)
            features = self.feature_extractor.getFeatureCode(image)
        
        return features

    def add(self, image: torch.Tensor, user_id: int):
        """ìƒˆë¡œìš´ ê²½í—˜ì„ ë²„í¼ì— ì¶”ê°€ (ê¸°ì¡´ ë°©ì‹ - í˜¸í™˜ì„± ìœ ì§€)"""
        
        with torch.no_grad():
            # ğŸ”¥ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ deviceë¡œ ê°•ì œ ì´ë™
            image_for_extraction = image.to(self.device)
            
            embedding = self._extract_feature_for_diversity(image_for_extraction)
            embedding_np = embedding.cpu().numpy().astype('float32')
            
            # Faiss ì •ê·œí™” (CPUì—ì„œ ìˆ˜í–‰)
            if FAISS_AVAILABLE:
                faiss.normalize_L2(embedding_np)

        if self.faiss_index is None:
            self._initialize_faiss()

        # ë‹¤ì–‘ì„± í™•ì¸
        if self.faiss_index is None or (FAISS_AVAILABLE and self.faiss_index.ntotal == 0):
            max_similarity = 0.0
        elif FAISS_AVAILABLE:
            distances, _ = self.faiss_index.search(embedding_np, k=1)
            max_similarity = distances[0][0]
        else:
            # Faiss ì—†ì„ ë•Œ PyTorch ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
            max_similarity = self._compute_pytorch_similarity(embedding_np)

        # ìƒˆë¡œìš´ ê²½í—˜ì´ë©´ ì €ì¥
        if max_similarity < self.similarity_threshold:
            if len(self.image_storage) >= self.buffer_size:
                self._cull()
            
            unique_id = len(self.image_storage)
            self.image_storage.append({
                'image': image.cpu().clone(),  # ğŸ”¥ í•­ìƒ CPUì— ì €ì¥
                'user_id': user_id,
                'id': unique_id
            })
            
            self.stored_embeddings.append(embedding_np.copy())
            if FAISS_AVAILABLE and self.faiss_index is not None:
                self.faiss_index.add_with_ids(embedding_np, np.array([unique_id]))
            self.metadata[unique_id] = {'user_id': user_id}
            
            print(f"[Buffer] âœ… Added diverse sample (ID: {unique_id}, User: {user_id}). "
                  f"Buffer: {len(self.image_storage)}/{self.buffer_size}")
        else:
            print(f"[Buffer] âš ï¸ Similar sample skipped (similarity: {max_similarity:.4f} >= {self.similarity_threshold})")

    def _compute_pytorch_similarity(self, new_embedding):
        """Faiss ì—†ì„ ë•Œ PyTorchë¡œ ìœ ì‚¬ë„ ê³„ì‚°"""
        if len(self.stored_embeddings) == 0:
            return 0.0
        
        new_emb = torch.tensor(new_embedding).flatten()
        max_sim = 0.0
        
        for stored_emb in self.stored_embeddings:
            stored_tensor = torch.tensor(stored_emb).flatten()
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = torch.cosine_similarity(new_emb.unsqueeze(0), stored_tensor.unsqueeze(0)).item()
            max_sim = max(max_sim, similarity)
        
        return max_sim

    def _cull(self):
        """ê°€ì¥ ì¤‘ë³µë˜ëŠ” ë°ì´í„° ì œê±° (ê¸°ì¡´ ë°©ì‹)"""
        if len(self.stored_embeddings) < 2:
            return

        print(f"[Buffer] ğŸ”„ Buffer full. Finding most redundant sample...")
        
        if FAISS_AVAILABLE and self.faiss_index is not None and self.faiss_index.ntotal >= 2:
            all_vectors = np.vstack(self.stored_embeddings)
            k = min(self.faiss_index.ntotal, 50)
            similarities, _ = self.faiss_index.search(all_vectors, k=k)
            diversity_scores = similarities.sum(axis=1) - 1.0
            cull_idx_in_storage = np.argmax(diversity_scores)
        else:
            # PyTorch ê¸°ë°˜ ë‹¤ì–‘ì„± ê³„ì‚°
            cull_idx_in_storage = self._find_most_redundant_pytorch()
        
        cull_unique_id = self.image_storage[cull_idx_in_storage]['id']

        # Faiss ì¸ë±ìŠ¤ì—ì„œ ì œê±°
        if FAISS_AVAILABLE and self.faiss_index is not None:
            try:
                self.faiss_index.remove_ids(np.array([cull_unique_id]))
            except Exception:
                self._rebuild_faiss_index_after_removal(cull_idx_in_storage)
        
        # ë©”íƒ€ë°ì´í„° ì •ë¦¬
        if cull_unique_id in self.metadata:
            del self.metadata[cull_unique_id]
        
        del self.image_storage[cull_idx_in_storage]
        del self.stored_embeddings[cull_idx_in_storage]
        
        print(f"[Buffer] ğŸ—‘ï¸ Removed redundant sample (ID: {cull_unique_id})")

    def _find_most_redundant_pytorch(self):
        """PyTorchë¡œ ê°€ì¥ ì¤‘ë³µë˜ëŠ” ìƒ˜í”Œ ì°¾ê¸°"""
        max_similarity = -1
        most_redundant_idx = 0
        
        for i, emb1 in enumerate(self.stored_embeddings):
            total_similarity = 0
            tensor1 = torch.tensor(emb1).flatten()
            
            for j, emb2 in enumerate(self.stored_embeddings):
                if i != j:
                    tensor2 = torch.tensor(emb2).flatten()
                    sim = torch.cosine_similarity(tensor1.unsqueeze(0), tensor2.unsqueeze(0)).item()
                    total_similarity += sim
            
            if total_similarity > max_similarity:
                max_similarity = total_similarity
                most_redundant_idx = i
        
        return most_redundant_idx

    def _rebuild_faiss_index_after_removal(self, removed_idx):
        """Faiss ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        if not FAISS_AVAILABLE:
            return
            
        print("[Buffer] ğŸ”§ Rebuilding Faiss index...")
        self._initialize_faiss()
        
        for i, (item, embedding) in enumerate(zip(self.image_storage, self.stored_embeddings)):
            if i != removed_idx and self.faiss_index is not None:
                self.faiss_index.add_with_ids(
                    embedding.reshape(1, -1), 
                    np.array([item['id']])
                )

    def sample_with_controlled_composition(self, batch_size: int, new_embedding: torch.Tensor = None, 
                                         current_user_id: int = None) -> Tuple[List, List]:
        """
        ğŸ”¥ ì œì–´ëœ ë°°ì¹˜ êµ¬ì„±ìœ¼ë¡œ ì •í™•í•œ ë¹„ìœ¨ ìƒ˜í”Œë§
        
        Args:
            batch_size: ëª©í‘œ ë°°ì¹˜ í¬ê¸°
            new_embedding: í˜„ì¬ ìƒˆë¡œìš´ ìƒ˜í”Œì˜ ì„ë² ë”© (í•˜ë“œ ë§ˆì´ë‹ìš©)
            current_user_id: í˜„ì¬ ì‚¬ìš©ì ID (ê¸ì •ìŒ ìƒì„±ìš©)
            
        Returns:
            Tuple[List, List]: (sampled_images, sampled_labels)
        """
        print(f"ğŸ¯ [Controlled] Creating controlled batch (size: {batch_size})")
        print(f"   Target positive ratio: {self.target_positive_ratio:.1%}")
        print(f"   Hard mining ratio: {self.hard_ratio:.1%}")
        
        if len(self.image_storage) == 0:
            return [], []

        # 1. ğŸ¯ ë°°ì¹˜ êµ¬ì„± ê³„íš ìˆ˜ë¦½
        target_positive_samples = max(2, int(batch_size * self.target_positive_ratio))
        if target_positive_samples % 2 == 1:
            target_positive_samples += 1
        target_positive_pairs = target_positive_samples // 2
        
        target_hard_samples = int(batch_size * self.hard_ratio)
        remaining_regular = batch_size - target_positive_samples - target_hard_samples
        
        if remaining_regular < 0:
            print(f"[Controlled] âš ï¸ Batch size too small, adjusting targets...")
            target_hard_samples = max(0, batch_size - target_positive_samples)
            remaining_regular = batch_size - target_positive_samples - target_hard_samples
        
        print(f"ğŸ“‹ [Controlled] Planned composition:")
        print(f"   Positive pairs: {target_positive_pairs} pairs ({target_positive_samples} samples)")
        print(f"   Hard samples: {target_hard_samples} samples")
        print(f"   Regular samples: {remaining_regular} samples")

        selected_indices = []
        selected_labels = []
        used_sample_ids = set()
        
        # 2. ğŸ”¥ ê¸ì •ìŒ ìƒ˜í”Œë§ (ê°™ì€ ì‚¬ìš©ìë¼ë¦¬)
        positive_samples_added = 0
        user_samples = {}
        
        # ì‚¬ìš©ìë³„ ìƒ˜í”Œ ê·¸ë£¹í•‘
        for i, item in enumerate(self.image_storage):
            user_id = item['user_id']
            if user_id not in user_samples:
                user_samples[user_id] = []
            user_samples[user_id].append((i, item))
        
        # 2ê°œ ì´ìƒ ìƒ˜í”Œì„ ê°€ì§„ ì‚¬ìš©ìë“¤ì—ì„œ ê¸ì •ìŒ ìƒì„±
        users_with_pairs = [uid for uid, samples in user_samples.items() if len(samples) >= 2]
        
        while positive_samples_added < target_positive_samples and users_with_pairs:
            user_id = random.choice(users_with_pairs)
            available_samples = [s for s in user_samples[user_id] if s[0] not in used_sample_ids]
            
            if len(available_samples) >= 2:
                # í•´ë‹¹ ì‚¬ìš©ìì—ì„œ 2ê°œ ìƒ˜í”Œ ì„ íƒ
                pair_samples = random.choices(available_samples, k=2)
                
                for idx, item in pair_samples:
                    selected_indices.append(idx)
                    selected_labels.append(item['user_id'])
                    used_sample_ids.add(idx)
                
                positive_samples_added += 2
                print(f"   âœ… Added positive pair from User {user_id}")
            else:
                users_with_pairs.remove(user_id)
        
        # 3. ğŸ”¥ í•˜ë“œ ìƒ˜í”Œ ë§ˆì´ë‹ (enable_hard_miningì´ Trueì¼ ë•Œ)
        hard_samples_added = 0
        
        if self.enable_hard_mining and target_hard_samples > 0 and new_embedding is not None:
            # í˜„ì¬ ì„ë² ë”©ê³¼ ìœ ì‚¬ë„ê°€ ë†’ì€ ì–´ë ¤ìš´ ìƒ˜í”Œë“¤ ì°¾ê¸°
            hard_candidates = []
            
            for i, item in enumerate(self.image_storage):
                if i not in used_sample_ids:
                    try:
                        stored_embedding = self.stored_embeddings[i]
                        similarity = np.dot(new_embedding.cpu().numpy().flatten(), 
                                          stored_embedding.flatten())
                        
                        # í˜„ì¬ ì‚¬ìš©ìì™€ ë‹¤ë¥¸ ì‚¬ìš©ìì˜ ìƒ˜í”Œ ì¤‘ì—ì„œ ìœ ì‚¬ë„ê°€ ë†’ì€ ê²ƒë“¤
                        if item['user_id'] != current_user_id and similarity > 0.5:
                            hard_candidates.append((i, item, similarity))
                    except:
                        continue
            
            # ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ì–´ë ¤ìš´ ìƒ˜í”Œë“¤ ì„ íƒ
            hard_candidates.sort(key=lambda x: x[2], reverse=True)
            
            for i, (idx, item, sim) in enumerate(hard_candidates[:target_hard_samples]):
                selected_indices.append(idx)
                selected_labels.append(item['user_id'])
                used_sample_ids.add(idx)
                hard_samples_added += 1
                print(f"   ğŸ”¥ Added hard sample: User {item['user_id']}, similarity={sim:.3f}")
        
        # 4. ğŸ”„ ì¼ë°˜ ìƒ˜í”Œë¡œ ë‚˜ë¨¸ì§€ ì±„ìš°ê¸°
        available_indices = [i for i in range(len(self.image_storage)) if i not in used_sample_ids]
        
        while len(selected_indices) < batch_size and available_indices:
            idx = random.choice(available_indices)
            item = self.image_storage[idx]
            
            selected_indices.append(idx)
            selected_labels.append(item['user_id'])
            used_sample_ids.add(idx)
            available_indices.remove(idx)
        
        # 5. ğŸ“Š ìµœì¢… ê²°ê³¼ ìˆ˜ì§‘
        sampled_images = []
        sampled_labels = []
        
        for idx in selected_indices:
            item = self.image_storage[idx]
            sampled_images.append(item['image'])
            sampled_labels.append(item['user_id'])
        
        # 6. ğŸ“ˆ ë°°ì¹˜ êµ¬ì„± ë¶„ì„
        final_positive_count = 0
        user_counts = {}
        for label in sampled_labels:
            user_counts[label] = user_counts.get(label, 0) + 1
        
        for count in user_counts.values():
            if count >= 2:
                final_positive_count += count
        
        print(f"ğŸ“Š [Controlled] Final batch composition:")
        print(f"   Total samples: {len(sampled_images)}")
        print(f"   Positive samples: {final_positive_count} ({final_positive_count/len(sampled_images):.1%})")
        print(f"   Hard samples: {hard_samples_added}")
        print(f"   Unique users: {len(user_counts)}")
        
        return sampled_images, sampled_labels

    def sample_with_replacement(self, batch_size: int, new_embedding: torch.Tensor = None, 
                              current_user_id: int = None) -> Tuple[List, List]:
        """
        ë¦¬í”Œë ˆì´ ìƒ˜í”Œë§ - ë‹¤ì–‘í•œ ì „ëµ ì§€ì›
        
        Args:
            batch_size: ë°°ì¹˜ í¬ê¸°
            new_embedding: í˜„ì¬ ìƒ˜í”Œ ì„ë² ë”© (í•˜ë“œ ë§ˆì´ë‹ìš©)
            current_user_id: í˜„ì¬ ì‚¬ìš©ì ID
            
        Returns:
            Tuple[List, List]: (sampled_images, sampled_labels)
        """
        if len(self.image_storage) == 0:
            return [], []
        
        # ìƒ˜í”Œë§ ì „ëµì— ë”°ë¼ ë‹¤ë¥¸ ë°©ë²• ì‚¬ìš©
        if self.sampling_strategy == "controlled":
            return self.sample_with_controlled_composition(batch_size, new_embedding, current_user_id)
        elif self.sampling_strategy == "balanced":
            return self._sample_balanced(batch_size)
        else:
            # ê¸°ë³¸ ëœë¤ ìƒ˜í”Œë§
            return self._sample_random(batch_size)

    def _sample_balanced(self, batch_size: int) -> Tuple[List, List]:
        """ì‚¬ìš©ì ê· í˜• ìƒ˜í”Œë§"""
        if len(self.image_storage) == 0:
            return [], []
        
        # ì‚¬ìš©ìë³„ ìƒ˜í”Œ ê·¸ë£¹í•‘
        user_samples = {}
        for i, item in enumerate(self.image_storage):
            user_id = item['user_id']
            if user_id not in user_samples:
                user_samples[user_id] = []
            user_samples[user_id].append((i, item))
        
        sampled_images = []
        sampled_labels = []
        
        # ê° ì‚¬ìš©ìì—ì„œ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§
        users = list(user_samples.keys())
        samples_per_user = max(1, batch_size // len(users))
        
        for user_id in users:
            user_items = user_samples[user_id]
            num_samples = min(samples_per_user, len(user_items))
            
            selected_items = random.choices(user_items, k=num_samples)
            
            for idx, item in selected_items:
                sampled_images.append(item['image'])
                sampled_labels.append(item['user_id'])
                
                if len(sampled_images) >= batch_size:
                    break
            
            if len(sampled_images) >= batch_size:
                break
        
        # ë¶€ì¡±í•˜ë©´ ëœë¤ìœ¼ë¡œ ì±„ìš°ê¸°
        while len(sampled_images) < batch_size:
            item = random.choice(self.image_storage)
            sampled_images.append(item['image'])
            sampled_labels.append(item['user_id'])
        
        return sampled_images[:batch_size], sampled_labels[:batch_size]

    def _sample_random(self, batch_size: int) -> Tuple[List, List]:
        """ê¸°ë³¸ ëœë¤ ìƒ˜í”Œë§"""
        if len(self.image_storage) == 0:
            return [], []
        
        # ëœë¤í•˜ê²Œ ìƒ˜í”Œ ì„ íƒ
        sample_indices = random.choices(range(len(self.image_storage)), k=batch_size)
        
        sampled_images = []
        sampled_labels = []
        
        for idx in sample_indices:
            item = self.image_storage[idx]
            sampled_images.append(item['image'])
            sampled_labels.append(item['user_id'])
        
        return sampled_images, sampled_labels

    def _setup_augmentation_transforms(self):
        """ë°ì´í„° ì¦ê°• ë³€í™˜ ì„¤ì • (ë³´ìˆ˜ì  ì†ê¸ˆ ì „ìš©)"""
        print("[Buffer] ğŸ¨ Setting up palmprint augmentation transforms...")
        
        if not self.enable_augmentation or self.aug_config is None:
            self.augmentation_transforms = None
            print("[Buffer] ğŸ¨ Data augmentation disabled")
            return
        
        try:
            # ê¸°ë³¸ ë³€í™˜ ë¦¬ìŠ¤íŠ¸
            transform_list = []
            
            # ê¸°í•˜í•™ì  ë³€í™˜ (ë§¤ìš° ë³´ìˆ˜ì )
            if hasattr(self.aug_config, 'enable_geometric') and self.aug_config.enable_geometric:
                max_rotation = getattr(self.aug_config, 'max_rotation_degrees', 3)  # 3ë„ë§Œ
                max_translation = getattr(self.aug_config, 'max_translation_ratio', 0.05)  # 5%ë§Œ
                
                transform_list.extend([
                    transforms.RandomRotation(degrees=max_rotation),
                    transforms.RandomAffine(degrees=0, translate=(max_translation, max_translation))
                ])
            
            # í•´ìƒë„ ì ì‘ (ë³´ìˆ˜ì )
            if hasattr(self.aug_config, 'enable_resolution_adaptation') and self.aug_config.enable_resolution_adaptation:
                # 80-100% í¬ê¸°ë¡œë§Œ ì œí•œ
                transform_list.append(transforms.RandomResizedCrop(128, scale=(0.8, 1.0)))
            
            # ì¡°ëª… ì¡°ê±´ ë³€í™” (ì†ê¸ˆì— ë„ì›€ë¨)
            if hasattr(self.aug_config, 'enable_noise') and self.aug_config.enable_noise:
                # ë°ê¸°/ëŒ€ë¹„ë§Œ ì•½ê°„ ì¡°ì •
                transform_list.append(transforms.ColorJitter(brightness=0.1, contrast=0.1))
            
            # ë³€í™˜ ì¡°í•©
            if transform_list:
                self.augmentation_transforms = transforms.Compose([
                    transforms.ToPILImage(),
                    *transform_list,
                    transforms.ToTensor()
                ])
                print(f"[Buffer] ğŸ¨ Palmprint augmentation enabled with {len(transform_list)} conservative transforms")
            else:
                self.augmentation_transforms = None
                print("[Buffer] ğŸ¨ No augmentation transforms configured")
                
        except Exception as e:
            print(f"[Buffer] âš ï¸ Augmentation setup failed: {e}")
            self.augmentation_transforms = None

    def _load_state(self):
        """ë²„í¼ ìƒíƒœ ë¡œë“œ"""
        print("[Buffer] ğŸ“‚ Loading buffer state...")
        
        if not self.state_file.exists():
            print("[Buffer] ğŸ“‚ No previous state found, starting fresh")
            return
        
        try:
            with open(self.state_file, 'rb') as f:
                state = pickle.load(f)
            
            self.image_storage = state.get('image_storage', [])
            self.stored_embeddings = state.get('stored_embeddings', [])
            self.metadata = state.get('metadata', {})
            
            print(f"[Buffer] ğŸ“‚ Loaded state: {len(self.image_storage)} samples")
            
            # Faiss ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
            if self.stored_embeddings:
                self._rebuild_faiss_index_from_state()
                
        except Exception as e:
            print(f"[Buffer] âš ï¸ State loading failed: {e}")
            # ì´ˆê¸°í™”
            self.image_storage = []
            self.stored_embeddings = []
            self.metadata = {}

    def _save_state(self):
        """ë²„í¼ ìƒíƒœ ì €ì¥"""
        try:
            state = {
                'image_storage': self.image_storage,
                'stored_embeddings': self.stored_embeddings,
                'metadata': self.metadata
            }
            
            with open(self.state_file, 'wb') as f:
                pickle.dump(state, f)
                
            print(f"[Buffer] ğŸ’¾ Saved buffer state: {len(self.image_storage)} samples")
            
        except Exception as e:
            print(f"[Buffer] âš ï¸ State saving failed: {e}")

    def _rebuild_faiss_index_from_state(self):
        """ìƒíƒœì—ì„œ Faiss ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        if not FAISS_AVAILABLE or not self.stored_embeddings:
            return
            
        print("[Buffer] ğŸ”§ Rebuilding Faiss index from saved state...")
        
        self._initialize_faiss()
        
        for i, (embedding, item) in enumerate(zip(self.stored_embeddings, self.image_storage)):
            if self.faiss_index is not None:
                embedding_np = np.array(embedding).astype('float32').reshape(1, -1)
                if FAISS_AVAILABLE:
                    faiss.normalize_L2(embedding_np)
                self.faiss_index.add_with_ids(embedding_np, np.array([item['id']]))
        
        print(f"[Buffer] âœ… Faiss index rebuilt with {len(self.stored_embeddings)} embeddings")

    def get_buffer_statistics(self):
        """ë²„í¼ ìƒíƒœ í†µê³„ ë°˜í™˜"""
        if len(self.image_storage) == 0:
            return {
                'total_samples': 0,
                'unique_users': 0,
                'user_distribution': {},
                'storage_reasons': {}
            }
        
        # ì‚¬ìš©ìë³„ ë¶„í¬
        user_distribution = {}
        storage_reasons = {}
        
        for item in self.image_storage:
            user_id = item['user_id']
            reason = item.get('storage_reason', 'unknown')
            
            user_distribution[user_id] = user_distribution.get(user_id, 0) + 1
            storage_reasons[reason] = storage_reasons.get(reason, 0) + 1
        
        return {
            'total_samples': len(self.image_storage),
            'unique_users': len(user_distribution),
            'user_distribution': user_distribution,
            'storage_reasons': storage_reasons,
            'buffer_utilization': len(self.image_storage) / self.buffer_size,
            'avg_samples_per_user': len(self.image_storage) / len(user_distribution) if user_distribution else 0
        }

    def clear_buffer(self):
        """ë²„í¼ ì™„ì „ ì´ˆê¸°í™”"""
        print("[Buffer] ğŸ—‘ï¸ Clearing buffer...")
        
        self.image_storage = []
        self.stored_embeddings = []
        self.metadata = {}
        
        if self.faiss_index is not None:
            self._initialize_faiss()
        
        print("[Buffer] âœ… Buffer cleared")

    def print_buffer_summary(self):
        """ë²„í¼ ìƒíƒœ ìš”ì•½ ì¶œë ¥"""
        stats = self.get_buffer_statistics()
        
        print(f"\nğŸ“Š [Buffer Summary]")
        print(f"   Total samples: {stats['total_samples']}/{self.buffer_size}")
        print(f"   Unique users: {stats['unique_users']}")
        print(f"   Utilization: {stats['buffer_utilizã…ation']:.1%}")
        print(f"   Avg samples/user: {stats['avg_samples_per_user']:.1f}")
        
        if stats['storage_reasons']:
            print(f"   Storage reasons:")
            for reason, count in stats['storage_reasons'].items():
                print(f"     {reason}: {count}")

print("âœ… learned íŒŒë¼ë¯¸í„° ì™„ì „ ì œê±°í•œ ë‹¨ìˆœí™”ëœ CoconutReplayBuffer ì™„ì„±!")