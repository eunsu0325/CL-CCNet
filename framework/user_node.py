# framework/user_node.py - Loop Closureë¥¼ ìœ„í•œ ì •ê·œí™” ì´ë¯¸ì§€ ì €ì¥ ë²„ì „

import torch
import numpy as np
from pathlib import Path
import json
import pickle
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import faiss
import base64
import io
from PIL import Image
import torch.nn.functional as F


class UserNode:
    """
    ì‚¬ìš©ìë³„ ë…¸ë“œ - ì„ë² ë”©ê³¼ ì´ë¯¸ì§€ ì €ì¥
    
    Features:
    - Mean embedding for fast matching
    - Registration image (raw) for visualization
    - Normalized tensors for Loop Closure
    - Update history tracking
    """
    
    def __init__(self, user_id: int, feature_dimension: int):
        self.user_id = user_id
        self.feature_dimension = feature_dimension
        
        # ì„ë² ë”© ê´€ë ¨
        self.mean_embedding = None
        self.embeddings = []
        
        # ì´ë¯¸ì§€ ì €ì¥
        self.registration_image = None  # ì›ë³¸ ì´ë¯¸ì§€ (ì‹œê°í™”ìš©)
        self.normalized_tensors = []    # ì •ê·œí™”ëœ í…ì„œ (Loop Closureìš©)
        self.max_stored_tensors = 10    # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ìµœëŒ€ ì €ì¥ ìˆ˜
        
        # ë©”íƒ€ë°ì´í„°
        self.sample_count = 0
        self.last_update = None
        self.creation_time = datetime.now()
        
    def update(self, embeddings: torch.Tensor, 
               registration_image: Optional[np.ndarray] = None,
               normalized_tensors: Optional[List[torch.Tensor]] = None):
        """
        ë…¸ë“œ ì—…ë°ì´íŠ¸
        
        Args:
            embeddings: [N, feature_dim] íŠ¹ì§• ë²¡í„°
            registration_image: ì›ë³¸ ì´ë¯¸ì§€ (ì‹œê°í™”ìš©)
            normalized_tensors: ì •ê·œí™”ëœ í…ì„œë“¤ (Loop Closureìš©)
        """
        # ì„ë² ë”© ì—…ë°ì´íŠ¸
        if isinstance(embeddings, torch.Tensor):
            embeddings_list = embeddings.cpu().numpy()
        else:
            embeddings_list = embeddings
            
        self.embeddings.extend(embeddings_list)
        self.sample_count += len(embeddings_list)
        
        # Mean embedding ì¬ê³„ì‚°
        self.mean_embedding = torch.tensor(
            np.mean(self.embeddings, axis=0),
            dtype=torch.float32
        )
        
        # ì‹œê°í™”ìš© ì›ë³¸ ì´ë¯¸ì§€
        if registration_image is not None:
            self.registration_image = registration_image
        
        # Loop Closureìš© ì •ê·œí™”ëœ í…ì„œ ì €ì¥
        if normalized_tensors is not None:
            self._store_normalized_tensors(normalized_tensors)
        
        self.last_update = datetime.now()
    
    def _store_normalized_tensors(self, new_tensors: List[torch.Tensor]):
        """ì •ê·œí™”ëœ í…ì„œ ì €ì¥ (ë‹¤ì–‘ì„± ê¸°ë°˜ ì„ íƒ)"""
        # ê¸°ì¡´ í…ì„œì™€ ìƒˆ í…ì„œ í•©ì¹˜ê¸°
        all_tensors = self.normalized_tensors + new_tensors
        
        if len(all_tensors) <= self.max_stored_tensors:
            # ì €ì¥ ê³µê°„ì´ ì¶©ë¶„í•˜ë©´ ëª¨ë‘ ì €ì¥
            self.normalized_tensors = [t.cpu() for t in all_tensors]
        else:
            # ë‹¤ì–‘ì„± ê¸°ë°˜ìœ¼ë¡œ ì„ íƒ
            selected_indices = self._select_diverse_samples(all_tensors, self.max_stored_tensors)
            self.normalized_tensors = [all_tensors[i].cpu() for i in selected_indices]
            
        print(f"[UserNode {self.user_id}] Stored {len(self.normalized_tensors)} normalized tensors")
    
    def _select_diverse_samples(self, tensors: List[torch.Tensor], n_select: int) -> List[int]:
        """ë‹¤ì–‘ì„± ê¸°ë°˜ ìƒ˜í”Œ ì„ íƒ"""
        if len(tensors) <= n_select:
            return list(range(len(tensors)))
        
        # ëª¨ë“  í…ì„œë¥¼ íŠ¹ì§• ë²¡í„°ë¡œ ë³€í™˜ (ì´ë¯¸ íŠ¹ì§•ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        features = []
        for t in tensors:
            if len(t.shape) > 1:  # ì´ë¯¸ì§€ í…ì„œì¸ ê²½ìš°
                # ê°„ë‹¨í•œ í‰ê·  í’€ë§ìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ
                feat = t.view(t.size(0), -1).mean(dim=1) if len(t.shape) == 3 else t.mean()
                features.append(feat)
            else:
                features.append(t)
        
        # Greedy ì„ íƒ: ê°€ì¥ ë©€ë¦¬ ë–¨ì–´ì§„ ìƒ˜í”Œë“¤ ì„ íƒ
        selected = [0]  # ì²« ë²ˆì§¸ ìƒ˜í”Œ ì„ íƒ
        
        while len(selected) < n_select:
            max_min_dist = -1
            best_idx = -1
            
            for i in range(len(features)):
                if i in selected:
                    continue
                    
                # ì„ íƒëœ ìƒ˜í”Œë“¤ê³¼ì˜ ìµœì†Œ ê±°ë¦¬ ê³„ì‚°
                min_dist = float('inf')
                for j in selected:
                    dist = torch.norm(features[i] - features[j]).item()
                    min_dist = min(min_dist, dist)
                
                # ìµœì†Œ ê±°ë¦¬ê°€ ê°€ì¥ í° ìƒ˜í”Œ ì„ íƒ
                if min_dist > max_min_dist:
                    max_min_dist = min_dist
                    best_idx = i
            
            if best_idx >= 0:
                selected.append(best_idx)
        
        return selected
    
    def get_loop_closure_data(self) -> Tuple[torch.Tensor, List[torch.Tensor]]:
        """
        Loop Closureë¥¼ ìœ„í•œ ë°ì´í„° ë°˜í™˜
        
        Returns:
            mean_embedding: í‰ê·  ì„ë² ë”©
            normalized_tensors: ì •ê·œí™”ëœ í…ì„œë“¤
        """
        return self.mean_embedding, self.normalized_tensors
    
    def image_to_base64(self) -> Optional[str]:
        """ì›ë³¸ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜ (ì‹œê°í™”ìš©)"""
        if self.registration_image is None:
            return None
        
        try:
            image_array = self.registration_image
            
            # numpy ë°°ì—´ í™•ì¸
            if not isinstance(image_array, np.ndarray):
                if hasattr(image_array, 'cpu'):
                    image_array = image_array.cpu().numpy()
            
            # uint8 í˜•íƒœ í™•ì¸
            if image_array.dtype == np.uint8:
                # ê·¸ëŒ€ë¡œ ì‚¬ìš©
                if len(image_array.shape) == 3 and image_array.shape[2] == 1:
                    image_array = image_array.squeeze(2)
            else:
                # float í˜•íƒœë©´ ë³€í™˜
                print(f"[UserNode] Converting from {image_array.dtype} to uint8")
                min_val = image_array.min()
                max_val = image_array.max()
                if max_val - min_val > 0:
                    image_array = (image_array - min_val) / (max_val - min_val)
                    image_array = (image_array * 255).astype(np.uint8)
                else:
                    image_array = np.full_like(image_array, 128, dtype=np.uint8)
            
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            pil_image = Image.fromarray(image_array, mode='L')
            
            # Base64 ì¸ì½”ë”©
            buffer = io.BytesIO()
            pil_image.save(buffer, format='PNG')
            img_str = base64.b64encode(buffer.getvalue()).decode()
            
            return img_str
            
        except Exception as e:
            print(f"[UserNode] Error converting image to base64: {e}")
            return None
    
    def to_dict(self) -> dict:
        """ì§ë ¬í™”ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ ë³€í™˜"""
        return {
            'user_id': self.user_id,
            'mean_embedding': self.mean_embedding.numpy().tolist() if self.mean_embedding is not None else None,
            'embeddings': [emb.tolist() if isinstance(emb, np.ndarray) else emb for emb in self.embeddings],
            'sample_count': self.sample_count,
            'last_update': self.last_update.isoformat() if self.last_update else None,
            'creation_time': self.creation_time.isoformat(),
            'feature_dimension': self.feature_dimension,
            'num_stored_tensors': len(self.normalized_tensors),
            'registration_image_shape': self.registration_image.shape if self.registration_image is not None else None
        }
    
    @classmethod
    def from_dict(cls, data: dict, feature_dimension: int) -> 'UserNode':
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ UserNode ë³µì›"""
        node = cls(data['user_id'], feature_dimension)
        
        if data.get('mean_embedding'):
            node.mean_embedding = torch.tensor(data['mean_embedding'], dtype=torch.float32)
        
        if data.get('embeddings'):
            node.embeddings = [np.array(emb) for emb in data['embeddings']]
        
        node.sample_count = data.get('sample_count', 0)
        
        if data.get('last_update'):
            node.last_update = datetime.fromisoformat(data['last_update'])
        
        if data.get('creation_time'):
            node.creation_time = datetime.fromisoformat(data['creation_time'])
        
        return node


class UserNodeManager:
    """
    ì‚¬ìš©ì ë…¸ë“œ ê´€ë¦¬ì - Loop Closure ì§€ì›
    
    Features:
    - User node creation and updates
    - Fast similarity search with Faiss
    - Loop closure data management
    - Persistence support
    """
    
    def __init__(self, config: Dict, device='cuda'):
        self.config = config
        self.device = device
        
        # ì„¤ì •
        self.feature_dimension = config.get('feature_dimension', 128)
        self.distance_threshold = config.get('distance_threshold', 0.5)
        self.storage_path = Path(config.get('storage_path', './user_nodes'))
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        # ì‚¬ìš©ì ë…¸ë“œ ì €ì¥ì†Œ
        self.nodes: Dict[int, UserNode] = {}
        
        # Faiss ì¸ë±ìŠ¤
        self.index = faiss.IndexFlatL2(self.feature_dimension)
        self.user_id_map = []  # ì¸ë±ìŠ¤ -> user_id ë§¤í•‘
        
        # í†µê³„
        self.total_verifications = 0
        self.successful_verifications = 0
        
        # ê¸°ì¡´ ë…¸ë“œ ë¡œë“œ
        self.load_nodes()
        
        print(f"[NodeManager] âœ… Initialized")
        print(f"  Feature dimension: {self.feature_dimension}")
        print(f"  Distance threshold: {self.distance_threshold}")
        print(f"  Loaded nodes: {len(self.nodes)}")
    
    def add_user(self, user_id: int, embeddings: torch.Tensor, 
                 registration_image: Optional[np.ndarray] = None,
                 normalized_tensors: Optional[List[torch.Tensor]] = None):
        """
        ìƒˆ ì‚¬ìš©ì ì¶”ê°€ ë˜ëŠ” ì—…ë°ì´íŠ¸
        
        Args:
            user_id: ì‚¬ìš©ì ID
            embeddings: íŠ¹ì§• ë²¡í„°ë“¤
            registration_image: ì›ë³¸ ì´ë¯¸ì§€ (ì‹œê°í™”ìš©)
            normalized_tensors: ì •ê·œí™”ëœ í…ì„œë“¤ (Loop Closureìš©)
        """
        if user_id in self.nodes:
            # ê¸°ì¡´ ì‚¬ìš©ì ì—…ë°ì´íŠ¸
            node = self.nodes[user_id]
            node.update(embeddings, registration_image, normalized_tensors)
            print(f"[NodeManager] Updated user {user_id}")
        else:
            # ìƒˆ ì‚¬ìš©ì ìƒì„±
            node = UserNode(user_id, self.feature_dimension)
            node.update(embeddings, registration_image, normalized_tensors)
            self.nodes[user_id] = node
            print(f"[NodeManager] Added new user {user_id}")
        
        # Faiss ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        self._update_faiss_index()
    
    def get_loop_closure_candidates(self, similarity_threshold: float = 0.8) -> List[Tuple[int, int, float]]:
        """
        Loop Closure í›„ë³´ ì°¾ê¸°
        
        Returns:
            List of (user_id1, user_id2, similarity) tuples
        """
        candidates = []
        user_ids = list(self.nodes.keys())
        
        for i in range(len(user_ids)):
            for j in range(i + 1, len(user_ids)):
                user1, user2 = user_ids[i], user_ids[j]
                node1, node2 = self.nodes[user1], self.nodes[user2]
                
                if node1.mean_embedding is not None and node2.mean_embedding is not None:
                    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = F.cosine_similarity(
                        node1.mean_embedding.unsqueeze(0),
                        node2.mean_embedding.unsqueeze(0)
                    ).item()
                    
                    if similarity > similarity_threshold:
                        candidates.append((user1, user2, similarity))
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        candidates.sort(key=lambda x: x[2], reverse=True)
        
        return candidates
    
    def get_loop_closure_data(self, user_ids: List[int]) -> Dict[int, Tuple[torch.Tensor, List[torch.Tensor]]]:
        """
        Loop Closureë¥¼ ìœ„í•œ ë°ì´í„° ë°˜í™˜
        
        Args:
            user_ids: ì‚¬ìš©ì ID ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Dict mapping user_id to (mean_embedding, normalized_tensors)
        """
        data = {}
        for user_id in user_ids:
            if user_id in self.nodes:
                node = self.nodes[user_id]
                data[user_id] = node.get_loop_closure_data()
        return data
    
    def _update_faiss_index(self):
        """Faiss ì¸ë±ìŠ¤ ì¬êµ¬ì„±"""
        # ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        self.index = faiss.IndexFlatL2(self.feature_dimension)
        self.user_id_map = []
        
        # ëª¨ë“  í‰ê·  ì„ë² ë”© ì¶”ê°€
        embeddings_list = []
        for user_id, node in self.nodes.items():
            if node.mean_embedding is not None:
                embeddings_list.append(node.mean_embedding.numpy())
                self.user_id_map.append(user_id)
        
        if embeddings_list:
            embeddings_array = np.array(embeddings_list).astype('float32')
            self.index.add(embeddings_array)
    
    def find_nearest_users(self, query_embedding: torch.Tensor, k: int = 10) -> List[Tuple[int, float]]:
        """ê°€ì¥ ê°€ê¹Œìš´ ì‚¬ìš©ì ì°¾ê¸°"""
        if self.index.ntotal == 0:
            return []
        
        # ì¿¼ë¦¬ ì¤€ë¹„
        if isinstance(query_embedding, torch.Tensor):
            query = query_embedding.cpu().numpy().reshape(1, -1).astype('float32')
        else:
            query = query_embedding.reshape(1, -1).astype('float32')
        
        # ê²€ìƒ‰
        k = min(k, self.index.ntotal)
        distances, indices = self.index.search(query, k)
        
        # ê²°ê³¼ ë³€í™˜
        results = []
        for i in range(k):
            if indices[0][i] >= 0:
                user_id = self.user_id_map[indices[0][i]]
                distance = float(distances[0][i])
                results.append((user_id, distance))
        
        return results
    
    def verify_user(self, probe_embedding: torch.Tensor, top_k: int = 10) -> Dict:
        """ì‚¬ìš©ì ì¸ì¦"""
        self.total_verifications += 1
        
        # ê°€ì¥ ê°€ê¹Œìš´ ì‚¬ìš©ì ì°¾ê¸°
        candidates = self.find_nearest_users(probe_embedding, k=top_k)
        
        if not candidates:
            return {
                'is_match': False,
                'matched_user': None,
                'distance': float('inf'),
                'confidence': 0.0,
                'top_k_results': []
            }
        
        # ìµœìƒìœ„ ë§¤ì¹˜
        best_user_id, best_distance = candidates[0]
        
        # L2 ê±°ë¦¬ë¥¼ ì½”ì‚¬ì¸ ê±°ë¦¬ë¡œ ë³€í™˜ (ê·¼ì‚¬)
        cosine_distance = best_distance / 2.0  # ì •ê·œí™”ëœ ë²¡í„° ê°€ì •
        
        # ì„ê³„ê°’ í™•ì¸
        is_match = cosine_distance <= self.distance_threshold
        
        if is_match:
            self.successful_verifications += 1
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = max(0.0, 1.0 - (cosine_distance / self.distance_threshold))
        
        return {
            'is_match': is_match,
            'matched_user': best_user_id if is_match else None,
            'distance': cosine_distance,
            'confidence': confidence,
            'top_k_results': candidates[:5],
            'threshold': self.distance_threshold
        }
    
    def get_node(self, user_id: int) -> Optional[UserNode]:
        """íŠ¹ì • ì‚¬ìš©ì ë…¸ë“œ ë°˜í™˜"""
        return self.nodes.get(user_id)
    
    def save_nodes(self):
        """ëª¨ë“  ë…¸ë“œ ì €ì¥"""
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'total_users': len(self.nodes),
            'feature_dimension': self.feature_dimension,
            'distance_threshold': self.distance_threshold,
            'total_verifications': self.total_verifications,
            'successful_verifications': self.successful_verifications,
            'save_time': datetime.now().isoformat()
        }
        
        metadata_path = self.storage_path / 'metadata.json'
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        # ê° ë…¸ë“œ ì €ì¥
        for user_id, node in self.nodes.items():
            node_path = self.storage_path / f'node_{user_id}.pkl'
            node_dict = node.to_dict()
            
            # ì •ê·œí™”ëœ í…ì„œëŠ” ë³„ë„ ì €ì¥
            tensors_path = self.storage_path / f'tensors_{user_id}.pt'
            if node.normalized_tensors:
                torch.save(node.normalized_tensors, tensors_path)
            
            # ì›ë³¸ ì´ë¯¸ì§€ëŠ” ë³„ë„ ì €ì¥
            if node.registration_image is not None:
                img_path = self.storage_path / f'img_{user_id}.npy'
                np.save(img_path, node.registration_image)
            
            with open(node_path, 'wb') as f:
                pickle.dump(node_dict, f)
        
        print(f"[NodeManager] ğŸ’¾ Saved {len(self.nodes)} nodes")
    
    def load_nodes(self):
        """ì €ì¥ëœ ë…¸ë“œ ë¡œë“œ"""
        metadata_path = self.storage_path / 'metadata.json'
        
        if not metadata_path.exists():
            print("[NodeManager] No saved nodes found")
            return
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        
        self.total_verifications = metadata.get('total_verifications', 0)
        self.successful_verifications = metadata.get('successful_verifications', 0)
        
        # ê° ë…¸ë“œ ë¡œë“œ
        node_files = list(self.storage_path.glob('node_*.pkl'))
        
        for node_file in node_files:
            user_id = int(node_file.stem.split('_')[1])
            
            with open(node_file, 'rb') as f:
                node_dict = pickle.load(f)
            
            node = UserNode.from_dict(node_dict, self.feature_dimension)
            
            # ì •ê·œí™”ëœ í…ì„œ ë¡œë“œ
            tensors_path = self.storage_path / f'tensors_{user_id}.pt'
            if tensors_path.exists():
                node.normalized_tensors = torch.load(tensors_path)
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
            img_path = self.storage_path / f'img_{user_id}.npy'
            if img_path.exists():
                node.registration_image = np.load(img_path)
            
            self.nodes[user_id] = node
        
        # Faiss ì¸ë±ìŠ¤ ì¬êµ¬ì„±
        self._update_faiss_index()
        
        print(f"[NodeManager] ğŸ“‚ Loaded {len(self.nodes)} nodes")
    
    def get_statistics(self) -> Dict:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        total_embeddings = sum(node.sample_count for node in self.nodes.values())
        total_tensors = sum(len(node.normalized_tensors) for node in self.nodes.values())
        
        return {
            'total_users': len(self.nodes),
            'total_embeddings': total_embeddings,
            'total_stored_tensors': total_tensors,
            'avg_embeddings_per_user': total_embeddings / len(self.nodes) if self.nodes else 0,
            'total_verifications': self.total_verifications,
            'successful_verifications': self.successful_verifications,
            'success_rate': self.successful_verifications / self.total_verifications if self.total_verifications > 0 else 0,
            'feature_dimension': self.feature_dimension,
            'distance_threshold': self.distance_threshold
        }