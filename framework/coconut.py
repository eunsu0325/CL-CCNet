"""
=== COCONUT STAGE 2: CONTINUAL LEARNING WITH INTELLIGENT REPLAY BUFFER ===

DESIGN RATIONALE (ë‹¨ìˆœí™”ë¨):
1. Focus on Replay Buffer innovation only
2. Use basic SupCon loss for stable continual learning  
3. Maintain checkpoint resume capability
4. Remove all W2ML complexity for clear paper contribution

CORE CONTRIBUTION:
- Diversity-based Intelligent Replay Buffer with Faiss acceleration
- True continual learning with complete state preservation
- Memory-efficient buffer management without catastrophic forgetting
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import copy
import json
import pickle
import time
from pathlib import Path
from tqdm import tqdm
import datetime

# Faiss import with fallback
try:
    import faiss
    import numpy as np
    FAISS_AVAILABLE = True
    print("[System] ğŸš€ Faiss available - Buffer optimization enabled")
except ImportError:
    FAISS_AVAILABLE = False
    print("[System] âš ï¸ Faiss not found - using PyTorch fallback")

from models.ccnet_model import ccnet
from framework.replay_buffer import CoconutReplayBuffer
from loss import SupConLoss  # ê¸°ì¡´ CCNetì˜ ë‹¨ìˆœí•œ SupConLoss ì‚¬ìš©
from datasets.palm_dataset import MyDataset
from torch.utils.data import DataLoader

class CoconutSystem:
    def __init__(self, config):
        """
        Continual Learning CoCoNut System (ë‹¨ìˆœí™”ë¨)
        
        FOCUS: Intelligent Replay Buffer for continual palmprint recognition
        """
        print("="*80)
        print("ğŸ¥¥ COCONUT STAGE 2: INTELLIGENT REPLAY BUFFER")
        print("="*80)
        print("ğŸ¯ CORE INNOVATION:")
        print("   - Diversity-based Replay Buffer with Faiss acceleration")
        print("   - True continual learning with checkpoint resume")
        print("   - Memory-efficient sample selection")
        print("   - Basic SupCon loss for stable learning")
        print("="*80)
        
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"[System] Using device: {self.device}")
        print(f"[System] Faiss status: {'Available' if FAISS_AVAILABLE else 'Fallback mode'}")
        
        # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì •
        self.checkpoint_dir = Path('/content/drive/MyDrive/CoCoNut_STAR/checkpoints')
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        # ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
        self._initialize_models()
        self._initialize_replay_buffer()
        self._initialize_basic_learning()
        
        # í•™ìŠµ ìƒíƒœ ì´ˆê¸°í™”
        self.learner_step_count = 0
        self.global_dataset_index = 0
        self._initialize_simple_stats()
        
        # ì´ì „ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë³µì›
        self._resume_from_latest_checkpoint()
        
        print(f"[System] ğŸ¥¥ CoCoNut ready!")
        print(f"[System] Starting from step: {self.learner_step_count}")
        print(f"[System] Dataset position: {self.global_dataset_index}")

    def _initialize_models(self):
        """ì˜ˆì¸¡ê¸°ì™€ í•™ìŠµê¸° ëª¨ë¸ì„ ìƒì„±í•˜ê³  ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("[System] Initializing CCNet models...")
        cfg_model = self.config.palm_recognizer
        
        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„±
        self.predictor_net = ccnet(num_classes=cfg_model.num_classes, weight=cfg_model.com_weight).to(self.device)
        self.learner_net = ccnet(num_classes=cfg_model.num_classes, weight=cfg_model.com_weight).to(self.device)
        
        # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
        weights_path = cfg_model.load_weights_folder
        print(f"[System] Loading pretrained weights from: {weights_path}")
        try:
            self.predictor_net.load_state_dict(torch.load(weights_path, map_location=self.device))
            self.learner_net.load_state_dict(self.predictor_net.state_dict())
            print("[System] âœ… Successfully loaded pretrained weights (Stage 1 â†’ Stage 2)")
        except FileNotFoundError:
            print(f"[System] âš ï¸ Pretrained weights not found. Starting with random weights.")
        except Exception as e:
            print(f"[System] âŒ Failed to load weights: {e}")
            
        self.predictor_net.eval()  # ì¶”ë¡ ìš©
        self.learner_net.train()   # í•™ìŠµìš©

    def _initialize_replay_buffer(self):
        """ë¦¬í”Œë ˆì´ ë²„í¼ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        print("[System] Initializing Intelligent Replay Buffer...")
        cfg_buffer = self.config.replay_buffer
        cfg_model = self.config.palm_recognizer

        buffer_storage_path = Path(cfg_buffer.storage_path)
        
        self.replay_buffer = CoconutReplayBuffer(
            config=cfg_buffer,
            storage_dir=buffer_storage_path,
            feature_dimension=cfg_model.feature_dimension 
        )
        
        # ë¦¬í”Œë ˆì´ ë²„í¼ì— íŠ¹ì§• ì¶”ì¶œê¸° ì„¤ì •
        self.replay_buffer.set_feature_extractor(self.learner_net)

    def _initialize_basic_learning(self):
        """ê¸°ë³¸ ì—°ì†í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (W2ML ì œê±°)"""
        print("[System] ğŸ¯ Initializing basic continual learning...")
        
        cfg_model = self.config.palm_recognizer
        cfg_loss = self.config.loss
        
        # Adam ì˜µí‹°ë§ˆì´ì €
        self.optimizer = optim.Adam(
            self.learner_net.parameters(), 
            lr=cfg_model.learning_rate
        )
        
        # ê¸°ë³¸ SupCon ì†ì‹¤ í•¨ìˆ˜
        self.contrastive_loss = SupConLoss(
            temperature=getattr(cfg_loss, 'temp', 0.07)
        )
        
        print("[System] âœ… Basic learning system initialized")
        print(f"[System] Optimizer: Adam (lr={cfg_model.learning_rate})")
        print(f"[System] Loss: SupConLoss (temp={getattr(cfg_loss, 'temp', 0.07)})")
        print(f"[System] Batch size: {cfg_model.batch_size}")

    def _initialize_simple_stats(self):
        """ë‹¨ìˆœí•œ í†µê³„ ì´ˆê¸°í™” (W2ML í†µê³„ ì œê±°)"""
        self.simple_stats = {
            'total_learning_steps': 0,
            'buffer_additions': 0,
            'buffer_skips': 0,
            'losses': [],
            'processing_times': [],
            'batch_sizes': [],
            'buffer_diversity_scores': []
        }

    def _resume_from_latest_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì‹œìŠ¤í…œ ë³µì›"""
        checkpoint_files = list(self.checkpoint_dir.glob('checkpoint_step_*.pth'))
        
        if not checkpoint_files:
            print("[Resume] ğŸ“‚ No checkpoints found - starting fresh")
            return
        
        # ê°€ì¥ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
        latest_checkpoint = max(checkpoint_files, key=lambda x: int(x.stem.split('_')[-1]))
        step_num = int(latest_checkpoint.stem.split('_')[-1])
        
        print(f"[Resume] ğŸ”„ Found checkpoint: {latest_checkpoint.name}")
        print(f"[Resume] ğŸ“ Resuming from step: {step_num}")
        
        try:
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(latest_checkpoint, map_location=self.device)
            
            # ëª¨ë¸ ìƒíƒœ ë³µì›
            self.learner_net.load_state_dict(checkpoint['learner_state_dict'])
            self.predictor_net.load_state_dict(checkpoint['predictor_state_dict'])
            
            # ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ë³µì›
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            
            # í•™ìŠµ ìƒíƒœ ë³µì›
            self.learner_step_count = checkpoint['step_count']
            self.global_dataset_index = checkpoint.get('global_dataset_index', 0)
            self.simple_stats = checkpoint.get('simple_stats', self.simple_stats)
            
            # ë¦¬í”Œë ˆì´ ë²„í¼ ìƒíƒœ ë³µì›
            buffer_checkpoint = self.checkpoint_dir / f'buffer_step_{step_num}.pkl'
            if buffer_checkpoint.exists():
                with open(buffer_checkpoint, 'rb') as f:
                    buffer_data = pickle.load(f)
                    self.replay_buffer.image_storage = buffer_data['image_storage']
                    self.replay_buffer.stored_embeddings = buffer_data.get('stored_embeddings', [])
                    self.replay_buffer.metadata = buffer_data['metadata']
                    if buffer_data.get('faiss_index_data'):
                        self.replay_buffer.faiss_index = faiss.deserialize_index(buffer_data['faiss_index_data'])
                    else:
                        self.replay_buffer.faiss_index = None
            
            print(f"[Resume] âœ… Successfully resumed from step {self.learner_step_count}")
            print(f"   Buffer size: {len(self.replay_buffer.image_storage)}")
            print(f"   Dataset position: {self.global_dataset_index}")
        
        except Exception as e:
            print(f"[Resume] âŒ Failed to resume: {e}")
            print(f"[Resume] ğŸ”„ Starting fresh instead")
            self.learner_step_count = 0
            self.global_dataset_index = 0

    def run_experiment(self):
        """CoCoNut Stage 2 ì—°ì†í•™ìŠµ ì‹¤í—˜ ì‹¤í–‰ (ë‹¨ìˆœí™”ë¨)"""
        print(f"[System] Starting continual learning from step {self.learner_step_count}...")

        # íƒ€ê²Ÿ ë°ì´í„°ì…‹ ì¤€ë¹„
        cfg_dataset = self.config.dataset
        target_dataset = MyDataset(txt=str(cfg_dataset.dataset_path), train=False)
        target_dataloader = DataLoader(target_dataset, batch_size=1, shuffle=False)
        
        # ì´ë¯¸ ì²˜ë¦¬í•œ ë°ì´í„°ë“¤ì€ ê±´ë„ˆë›°ê¸°
        dataset_list = list(target_dataloader)
        total_steps = len(dataset_list)
        
        if self.global_dataset_index >= total_steps:
            print(f"[System] All data already processed! ({self.global_dataset_index}/{total_steps})")
            return
        
        print(f"[System] Resuming from dataset position {self.global_dataset_index}/{total_steps}")
        print(f"[System] Remaining data: {total_steps - self.global_dataset_index}")

        # ì´ì–´ì„œ í•™ìŠµí•  ë°ì´í„°ë§Œ ì¶”ì¶œ
        remaining_data = dataset_list[self.global_dataset_index:]
        
        for data_offset, (datas, user_id) in enumerate(tqdm(remaining_data, desc="Continual Learning")):
            
            # ì „ì²´ ë°ì´í„°ì…‹ì—ì„œì˜ í˜„ì¬ ìœ„ì¹˜ ì—…ë°ì´íŠ¸
            self.global_dataset_index = self.global_dataset_index + data_offset
            
            primary_image = datas[0].squeeze(0)
            user_id = user_id.item()

            # í•œ í”„ë ˆì„ ì²˜ë¦¬
            self.process_single_frame(primary_image, user_id)

            # ì„¤ì •ëœ ë¹ˆë„ì— ë”°ë¼ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            save_frequency = getattr(self.config.continual_learner, 'intermediate_save_frequency', 50)
            if save_frequency > 0 and self.learner_step_count > 0 and self.learner_step_count % save_frequency == 0:
                self._save_complete_checkpoint()

            # ì¤‘ê°„ ê²°ê³¼ ë¡œê¹…
            if self.learner_step_count % 100 == 0 and self.learner_step_count > 0:
                self._log_progress(self.global_dataset_index, total_steps)

        # ë§ˆì§€ë§‰ ë°ì´í„° ì²˜ë¦¬ í›„ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        self.global_dataset_index = total_steps

        # ì‹¤í—˜ ì¢…ë£Œ í›„ ìµœì¢… ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        print("\n[System] Continual Learning experiment finished.")
        self._save_complete_checkpoint()
        self._final_analysis()
        self.save_system_state()

    def process_single_frame(self, image: torch.Tensor, user_id: int):
        """
        ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ (ë‹¨ìˆœí™”ë¨)
        
        SIMPLIFIED PROCESS:
        1. Extract features using learner network
        2. Add to intelligent replay buffer (diversity-based)
        3. Perform basic continual learning if conditions met
        """
        image = image.to(self.device)

        # 1. ì˜ˆì¸¡ê¸°ë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì¸ì¦
        self.predictor_net.eval()
        with torch.no_grad():
            embedding_from_predictor = self.predictor_net.getFeatureCode(image)
        
        # 2. í•™ìŠµê¸°ë¥¼ í†µí•œ ìµœì‹  íŠ¹ì§• ì¶”ì¶œ
        self.learner_net.eval()
        with torch.no_grad():
            latest_embedding = self.learner_net.getFeatureCode(image)
        self.learner_net.train()
        
        # 3. ë¦¬í”Œë ˆì´ ë²„í¼ì— ì¶”ê°€ (ë‹¤ì–‘ì„± ê¸°ë°˜)
        buffer_size_before = len(self.replay_buffer.image_storage)
        self.replay_buffer.add(image, user_id)
        buffer_size_after = len(self.replay_buffer.image_storage)
        
        # ì¶”ê°€ ì—¬ë¶€ í†µê³„ ì—…ë°ì´íŠ¸
        if buffer_size_after > buffer_size_before:
            self.simple_stats['buffer_additions'] += 1
        else:
            self.simple_stats['buffer_skips'] += 1
        
        # 4. í˜„ì¬ ë²„í¼ ìƒíƒœ í™•ì¸
        buffer_size = len(self.replay_buffer.image_storage)
        unique_users = len(set([item['user_id'] for item in self.replay_buffer.image_storage]))
        
        # ìµœì†Œ ì¡°ê±´: 2ëª… ì´ìƒì˜ ì‚¬ìš©ì (ëŒ€ì¡°í•™ìŠµì„ ìœ„í•œ ìµœì†Œ ë‹¤ì–‘ì„±)
        if unique_users < 2:
            print(f"[Learning] ğŸ“Š Waiting for diversity (Dataset pos: {self.global_dataset_index}):")
            print(f"   Buffer size: {buffer_size}")
            print(f"   Unique users: {unique_users}/2 minimum")
            return
        
        # 5. ì²« ë²ˆì§¸ í•™ìŠµ ì‹œì‘ ì•Œë¦¼
        if unique_users == 2 and buffer_size <= 3:
            print(f"\nğŸ‰ [Learning] CONTINUAL LEARNING ACTIVATED!")
            print(f"   Minimum diversity achieved: {unique_users} users")
            print(f"   Target batch size: {self.config.palm_recognizer.batch_size}")
        
        # 6. ê¸°ë³¸ ì—°ì†í•™ìŠµ ì‹¤í–‰
        self._basic_continual_learning(image, user_id)

    def _basic_continual_learning(self, new_image, new_user_id):
        """
        ê¸°ë³¸ ì—°ì†í•™ìŠµ ìˆ˜í–‰ (W2ML ë³µì¡ì„± ì œê±°)
        
        SIMPLIFIED LEARNING:
        1. Create batch with new sample + replay samples
        2. Extract embeddings using learner network
        3. Compute basic SupCon loss
        4. Perform gradient update
        """
        
        # í•™ìŠµ ìŠ¤í… ì¦ê°€
        self.learner_step_count += 1
        
        print(f"[Learning] {'='*50}")
        print(f"[Learning] BASIC CONTINUAL STEP {self.learner_step_count}")
        print(f"[Learning] {'='*50}")
        
        cfg_learner = self.config.continual_learner
        cfg_model = self.config.palm_recognizer
        target_batch_size = cfg_model.batch_size

        # ë°°ì¹˜ êµ¬ì„±: ìƒˆ ì´ë¯¸ì§€ 1ì¥ + ë²„í¼ì—ì„œ ë‚˜ë¨¸ì§€
        replay_count = target_batch_size - 1
        replay_images, replay_labels = self.replay_buffer.sample_with_replacement(replay_count)
        
        all_images = [new_image] + replay_images
        all_labels = [new_user_id] + replay_labels
        
        actual_batch_size = len(all_images)
        
        print(f"[Learning] Batch Analysis:")
        print(f"   Target batch size: {target_batch_size}")
        print(f"   Actual batch size: {actual_batch_size}")
        print(f"   Current user: {new_user_id}")
        print(f"   Replay samples: {len(replay_images)}")
        
        # ë‹¤ì–‘ì„± ë¶„ì„
        unique_users = len(set(all_labels))
        user_distribution = {}
        for label in all_labels:
            user_distribution[label] = user_distribution.get(label, 0) + 1
        
        print(f"   Unique users: {unique_users}")
        print(f"   User distribution: {dict(sorted(user_distribution.items()))}")
        
        # ì—°ì†í•™ìŠµ ì—í¬í¬ë“¤ ì‹¤í–‰
        total_loss = 0.0
        processing_start = time.time()
        
        for epoch in range(cfg_learner.adaptation_epochs):
            print(f"[Learning] ğŸ”„ Adaptation epoch {epoch+1}/{cfg_learner.adaptation_epochs}")
            
            epoch_loss = self._run_basic_learning_step(all_images, all_labels)
            total_loss += epoch_loss
        
        processing_time = time.time() - processing_start
        average_loss = total_loss / cfg_learner.adaptation_epochs
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self.simple_stats['total_learning_steps'] += 1
        self.simple_stats['losses'].append(average_loss)
        self.simple_stats['processing_times'].append(processing_time)
        self.simple_stats['batch_sizes'].append(actual_batch_size)
        
        # ë²„í¼ ë‹¤ì–‘ì„± í†µê³„
        diversity_stats = self.replay_buffer.get_diversity_stats()
        self.simple_stats['buffer_diversity_scores'].append(diversity_stats['diversity_score'])
        
        print(f"[Learning] ğŸ“Š Step {self.learner_step_count} Results:")
        print(f"   Average loss: {average_loss:.6f}")
        print(f"   Processing time: {processing_time*1000:.2f}ms")
        print(f"   Buffer diversity: {diversity_stats['diversity_score']:.3f}")
        print(f"   Buffer size: {diversity_stats['total_samples']}")
        print(f"   Unique users: {diversity_stats['unique_users']}")
        
        # ëª¨ë¸ ë™ê¸°í™” ì²´í¬
        if self.learner_step_count % cfg_learner.sync_frequency == 0:
            self._sync_weights()

    def _run_basic_learning_step(self, images: list, labels: list):
        """
        ê¸°ë³¸ í•™ìŠµ ìŠ¤í… ìˆ˜í–‰ (W2ML ë³µì¡ì„± ì œê±°)
        
        SIMPLE LEARNING:
        1. Extract embeddings from all images
        2. Compute basic SupCon loss
        3. Perform gradient update
        """
        
        print(f"[Learning] ğŸ§  Processing {len(images)} samples with basic SupCon")
        
        # 1. í•™ìŠµì„ ìœ„í•´ train ëª¨ë“œ ì„¤ì •
        self.learner_net.train()
        self.optimizer.zero_grad()
        
        # 2. ì„ë² ë”© ì¶”ì¶œ
        embeddings = []
        for i, img in enumerate(images):
            img = img.to(self.device)
            if len(img.shape) == 3:
                img = img.unsqueeze(0)
            
            # Forward pass with gradient computation
            embedding = self.learner_net.getFeatureCode(img)
            embeddings.append(embedding)
        
        # 3. ë°°ì¹˜ í…ì„œ êµ¬ì„±
        embeddings_tensor = torch.cat(embeddings, dim=0)  # [batch_size, feature_dim]
        labels_tensor = torch.tensor(labels, dtype=torch.long, device=self.device)
        
        # 4. SupCon ì†ì‹¤ ê³„ì‚°
        embeddings_for_loss = embeddings_tensor.unsqueeze(1)  # [batch_size, 1, feature_dim]
        
        print("[Learning] ğŸ¯ Computing basic SupCon loss...")
        
        # ê¸°ë³¸ SupCon ì†ì‹¤ ê³„ì‚°
        loss = self.contrastive_loss(embeddings_for_loss, labels_tensor)
        
        # 5. ì—­ì „íŒŒ
        if loss.requires_grad:
            loss.backward()
            self.optimizer.step()
            print("[Learning] âœ… Gradient update completed")
        else:
            print("[Learning] âš ï¸ No gradient - loss computation issue")
        
        print(f"[Learning] âœ… Basic Loss: {loss.item():.6f}")
        
        return loss.item()

    def _sync_weights(self):
        """í•™ìŠµê¸°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì˜ˆì¸¡ê¸°ë¡œ ë³µì‚¬ (ë‹¨ìˆœí™”ë¨)"""
        
        self.predictor_net.load_state_dict(self.learner_net.state_dict())
        self.predictor_net.eval()
        
        print(f"\n[Sync] ğŸ”„ MODEL SYNCHRONIZATION")
        print(f"[Sync] {'='*50}")
        
        # ìµœê·¼ ì„±ëŠ¥ ë¶„ì„
        recent_steps = min(10, len(self.simple_stats['losses']))
        if recent_steps > 0:
            recent_losses = self.simple_stats['losses'][-recent_steps:]
            recent_diversity = self.simple_stats['buffer_diversity_scores'][-recent_steps:]
            recent_batch_sizes = self.simple_stats['batch_sizes'][-recent_steps:]
            
            avg_loss = sum(recent_losses) / len(recent_losses)
            avg_diversity = sum(recent_diversity) / len(recent_diversity)
            avg_batch_size = sum(recent_batch_sizes) / len(recent_batch_sizes)
            
            print(f"[Sync] ğŸ“Š Recent {recent_steps} steps analysis:")
            print(f"   Average loss: {avg_loss:.6f}")
            print(f"   Average diversity: {avg_diversity:.3f}")
            print(f"   Average batch size: {avg_batch_size:.1f}")
            print(f"   Total buffer additions: {self.simple_stats['buffer_additions']}")
            print(f"   Total buffer skips: {self.simple_stats['buffer_skips']}")
            
        print(f"[Sync] âœ… Predictor updated!")
        print(f"[Sync] {'='*50}\n")

    def _save_complete_checkpoint(self):
        """ì™„ì „í•œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        
        step = self.learner_step_count
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì²´í¬í¬ì¸íŠ¸ ë°ì´í„° ì¤€ë¹„
        checkpoint = {
            'step_count': step,
            'global_dataset_index': self.global_dataset_index,
            'timestamp': timestamp,
            'learner_state_dict': self.learner_net.state_dict(),
            'predictor_state_dict': self.predictor_net.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'simple_stats': self.simple_stats,
            'config_info': {
                'batch_size': self.config.palm_recognizer.batch_size,
                'learning_rate': self.config.palm_recognizer.learning_rate,
                'loss_temperature': getattr(self.config.loss, 'temp', 0.07),
            }
        }
        
        # ë©”ì¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        checkpoint_path = self.checkpoint_dir / f'checkpoint_step_{step}.pth'
        torch.save(checkpoint, checkpoint_path)
        
        # ë¦¬í”Œë ˆì´ ë²„í¼ ìƒíƒœ ì €ì¥
        buffer_data = {
            'image_storage': self.replay_buffer.image_storage,
            'stored_embeddings': getattr(self.replay_buffer, 'stored_embeddings', []),
            'metadata': self.replay_buffer.metadata,
            'faiss_index_data': faiss.serialize_index(self.replay_buffer.faiss_index) if self.replay_buffer.faiss_index else None
        }
        buffer_path = self.checkpoint_dir / f'buffer_step_{step}.pkl'
        with open(buffer_path, 'wb') as f:
            pickle.dump(buffer_data, f)
        
        # ìƒì„¸ í†µê³„ ì €ì¥
        stats_data = {
            'step': step,
            'global_dataset_index': self.global_dataset_index,
            'timestamp': timestamp,
            'learning_progress': {
                'total_steps': self.simple_stats['total_learning_steps'],
                'buffer_additions': self.simple_stats['buffer_additions'],
                'buffer_skips': self.simple_stats['buffer_skips'],
                'avg_loss': sum(self.simple_stats['losses'][-10:]) / min(10, len(self.simple_stats['losses'])) if self.simple_stats['losses'] else 0,
                'avg_diversity': sum(self.simple_stats['buffer_diversity_scores'][-10:]) / min(10, len(self.simple_stats['buffer_diversity_scores'])) if self.simple_stats['buffer_diversity_scores'] else 0,
            },
            'buffer_status': {
                'size': len(self.replay_buffer.image_storage),
                'diversity': len(set([item['user_id'] for item in self.replay_buffer.image_storage])),
                'max_size': self.replay_buffer.buffer_size
            }
        }
        
        stats_path = self.checkpoint_dir / f'stats_step_{step}.json'
        with open(stats_path, 'w') as f:
            json.dump(stats_data, f, indent=2)
        
        # ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬ (ìµœê·¼ 5ê°œë§Œ ìœ ì§€)
        self._cleanup_old_checkpoints()
        
        print(f"[Checkpoint] ğŸ’¾ Complete checkpoint saved:")
        print(f"   ğŸ“ Model: checkpoint_step_{step}.pth")
        print(f"   ğŸ“ Buffer: buffer_step_{step}.pkl") 
        print(f"   ğŸ“ Stats: stats_step_{step}.json")
        print(f"   ğŸ“ Dataset position: {self.global_dataset_index}")

    def _cleanup_old_checkpoints(self, keep_last=5):
        """ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ë“¤ ì •ë¦¬"""
        
        checkpoint_files = list(self.checkpoint_dir.glob('checkpoint_step_*.pth'))
        if len(checkpoint_files) <= keep_last:
            return
        
        # ìŠ¤í… ë²ˆí˜¸ë¡œ ì •ë ¬í•˜ê³  ì˜¤ë˜ëœ ê²ƒë“¤ ì‚­ì œ
        checkpoint_files.sort(key=lambda x: int(x.stem.split('_')[-1]))
        files_to_delete = checkpoint_files[:-keep_last]
        
        for file_path in files_to_delete:
            step_num = int(file_path.stem.split('_')[-1])
            
            # ê´€ë ¨ íŒŒì¼ë“¤ ëª¨ë‘ ì‚­ì œ
            file_path.unlink()  # checkpoint_step_X.pth
            
            buffer_file = self.checkpoint_dir / f'buffer_step_{step_num}.pkl'
            if buffer_file.exists():
                buffer_file.unlink()
                
            stats_file = self.checkpoint_dir / f'stats_step_{step_num}.json'
            if stats_file.exists():
                stats_file.unlink()
        
        print(f"[Cleanup] ğŸ—‘ï¸ Cleaned up {len(files_to_delete)} old checkpoints")

    def _log_progress(self, step, total_steps):
        """ì§„í–‰ ìƒí™© ë¡œê¹… (ë‹¨ìˆœí™”ë¨)"""
        
        print(f"\n[Progress] Step {step}/{total_steps} ({step/total_steps*100:.1f}%)")
        
        if len(self.simple_stats['losses']) > 0:
            recent_loss = self.simple_stats['losses'][-1]
            print(f"  - Recent loss: {recent_loss:.6f}")
        
        if len(self.simple_stats['buffer_diversity_scores']) > 0:
            recent_diversity = self.simple_stats['buffer_diversity_scores'][-1]
            print(f"  - Buffer diversity: {recent_diversity:.3f}")
        
        print(f"  - Total learning steps: {self.simple_stats['total_learning_steps']}")
        print(f"  - Buffer additions: {self.simple_stats['buffer_additions']}")
        print(f"  - Buffer skips: {self.simple_stats['buffer_skips']}")

    def _final_analysis(self):
        """ìµœì¢… ë¶„ì„ (ë‹¨ìˆœí™”ë¨)"""
        
        print("\n" + "="*80)
        print("FINAL CONTINUAL LEARNING ANALYSIS")
        print("="*80)
        
        total_steps = self.simple_stats['total_learning_steps']
        total_additions = self.simple_stats['buffer_additions']
        total_skips = self.simple_stats['buffer_skips']
        
        if total_steps > 0:
            avg_loss = sum(self.simple_stats['losses']) / len(self.simple_stats['losses'])
            avg_diversity = sum(self.simple_stats['buffer_diversity_scores']) / len(self.simple_stats['buffer_diversity_scores'])
            avg_batch_size = sum(self.simple_stats['batch_sizes']) / len(self.simple_stats['batch_sizes'])
            
            print(f"ğŸ“Š Continual Learning Statistics:")
            print(f"   ğŸ”„ Total adaptation steps: {total_steps}")
            print(f"   ğŸ’¡ Average loss: {avg_loss:.6f}")
            print(f"   ğŸ¯ Average diversity: {avg_diversity:.3f}")
            print(f"   ğŸ“ Average batch size: {avg_batch_size:.1f}")
            print(f"   âœ… Buffer additions: {total_additions}")
            print(f"   âš ï¸ Buffer skips: {total_skips}")
            print(f"   ğŸ“ Final dataset position: {self.global_dataset_index}")
            
            # ë²„í¼ íš¨ìœ¨ì„± ë¶„ì„
            total_processed = total_additions + total_skips
            addition_rate = (total_additions / total_processed * 100) if total_processed > 0 else 0
            print(f"   ğŸ“ˆ Buffer addition rate: {addition_rate:.1f}%")
            
            # ë°°ì¹˜ í¬ê¸° ë‹¬ì„±ë¥ 
            target_batch_size = self.config.palm_recognizer.batch_size
            batch_size_achievement = (avg_batch_size / target_batch_size) * 100
            print(f"   ğŸ¯ Batch size achievement: {batch_size_achievement:.1f}%")
            
            # ìµœì¢… í‰ê°€
            print(f"\nğŸ”¬ Intelligent Replay Buffer Performance:")
            print(f"   ğŸ“– Diversity-based selection: âœ… {'Excellent' if addition_rate < 70 else 'Good' if addition_rate < 80 else 'Moderate'}")
            print(f"   ğŸš€ Faiss acceleration: âœ… {'Active' if FAISS_AVAILABLE else 'Fallback mode'}")
            print(f"   ğŸ¯ Batch size consistency: âœ… {'Excellent' if batch_size_achievement > 95 else 'Good'}")
            print(f"   ğŸ”„ Checkpoint resume: âœ… Implemented")
            
            if addition_rate < 70 and batch_size_achievement > 95:
                print(f"   ğŸ‰ INTELLIGENT REPLAY BUFFER: EXCELLENT PERFORMANCE!")
            elif addition_rate < 80 and batch_size_achievement > 90:
                print(f"   âœ… INTELLIGENT REPLAY BUFFER: GOOD PERFORMANCE")
            else:
                print(f"   ğŸ”§ INTELLIGENT REPLAY BUFFER: NEEDS OPTIMIZATION")
                
        print("="*80)

    def save_system_state(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥ (ìµœì¢… í˜¸ì¶œìš©)"""
        
        # ì‚¬ìš©ì ì§€ì • ì €ì¥ ê²½ë¡œ
        custom_save_path = Path('/content/drive/MyDrive/CoCoNut_STAR')
        custom_save_path.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ë³¸ ì €ì¥ ê²½ë¡œë„ ìœ ì§€
        storage_path = Path(self.config.replay_buffer.storage_path)
        storage_path.mkdir(parents=True, exist_ok=True)
        
        # ìµœì¢… í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©ì ì§€ì • ê²½ë¡œì— ì €ì¥
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì‚¬ìš©ì ì§€ì • ê²½ë¡œì— ì €ì¥
        custom_learner_path = custom_save_path / f'coconut_replay_model_{timestamp}.pth'
        custom_predictor_path = custom_save_path / f'coconut_predictor_model_{timestamp}.pth'
        
        torch.save(self.learner_net.state_dict(), custom_learner_path)
        torch.save(self.predictor_net.state_dict(), custom_predictor_path)
        
        # ê¸°ë³¸ ê²½ë¡œì—ë„ ì €ì¥ (í˜¸í™˜ì„±)
        learner_path = storage_path / 'coconut_replay_learner.pth'
        predictor_path = storage_path / 'coconut_replay_predictor.pth'
        torch.save(self.learner_net.state_dict(), learner_path)
        torch.save(self.predictor_net.state_dict(), predictor_path)
        
        # í†µê³„ë¥¼ ì‚¬ìš©ì ì§€ì • ê²½ë¡œì— ì €ì¥
        custom_stats_path = custom_save_path / f'coconut_replay_stats_{timestamp}.json'
        stats_path = storage_path / 'coconut_replay_stats.json'
        
        import json
        stats_to_save = {
            'total_learning_steps': self.simple_stats['total_learning_steps'],
            'buffer_additions': self.simple_stats['buffer_additions'],
            'buffer_skips': self.simple_stats['buffer_skips'],
            'losses': self.simple_stats['losses'],
            'processing_times': self.simple_stats['processing_times'],
            'batch_sizes': self.simple_stats['batch_sizes'],
            'buffer_diversity_scores': self.simple_stats['buffer_diversity_scores'],
            # ì„¤ì • ì •ë³´
            'target_batch_size': self.config.palm_recognizer.batch_size,
            'loss_temperature': getattr(self.config.loss, 'temp', 0.07),
            'faiss_available': FAISS_AVAILABLE,
            'gpu_available': torch.cuda.is_available(),
            # ì¶”ê°€ ì •ë³´
            'save_timestamp': timestamp,
            'total_adaptation_steps': self.learner_step_count,
            'final_dataset_position': self.global_dataset_index,
            'model_architecture': 'CCNet',
            'loss_function': 'SupConLoss',
            'core_innovation': 'Intelligent Replay Buffer',
            'continual_learning': True,
            'checkpoint_resume': True
        }
        
        # ì–‘ìª½ ê²½ë¡œì— í†µê³„ ì €ì¥
        with open(custom_stats_path, 'w') as f:
            json.dump(stats_to_save, f, indent=2)
        with open(stats_path, 'w') as f:
            json.dump(stats_to_save, f, indent=2)
        
        # README íŒŒì¼ ìƒì„±
        readme_content = f"""# CoCoNut Intelligent Replay Buffer Trained Model

## ëª¨ë¸ ì •ë³´
- ì €ì¥ ì‹œê°„: {timestamp}
- ì´ ì ì‘ ìŠ¤í…: {self.learner_step_count}
- ë°ì´í„°ì…‹ ì™„ë£Œ: {self.global_dataset_index}ê°œ ì²˜ë¦¬
- ë²„í¼ ì¶”ê°€: {self.simple_stats['buffer_additions']}ê°œ
- ë²„í¼ ìŠ¤í‚µ: {self.simple_stats['buffer_skips']}ê°œ
- ì•„í‚¤í…ì²˜: CCNet with Intelligent Replay Buffer
- ì²´í¬í¬ì¸íŠ¸ ë³µì›: ì§€ì›ë¨

## í•µì‹¬ ê¸°ì—¬
- **Diversity-based Replay Strategy**: Faiss ê°€ì† ìœ ì‚¬ë„ ê¸°ë°˜ ìƒ˜í”Œ ì„ íƒ
- **Intelligent Buffer Management**: ì¤‘ë³µ ìƒ˜í”Œ ìë™ ì œê±°
- **True Continual Learning**: ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ì¤‘ë‹¨/ì¬ê°œ ì‹œìŠ¤í…œ

## íŒŒì¼ ì„¤ëª…
- `coconut_replay_model_{timestamp}.pth`: ìµœì¢… í•™ìŠµëœ ëª¨ë¸ (learner)
- `coconut_predictor_model_{timestamp}.pth`: ì˜ˆì¸¡ìš© ëª¨ë¸ (predictor)
- `coconut_replay_stats_{timestamp}.json`: í•™ìŠµ í†µê³„ ë° ì„±ëŠ¥ ì§€í‘œ

## ëª¨ë¸ ë¡œë“œ ë°©ë²•

```python
import torch
from models.ccnet_model import ccnet

# ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„±
model = ccnet(num_classes=600, weight=0.8)

# í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
model.load_state_dict(torch.load('coconut_replay_model_{timestamp}.pth'))
model.eval()

# íŠ¹ì§• ì¶”ì¶œ ì‚¬ìš© ì˜ˆì‹œ
with torch.no_grad():
    features = model.getFeatureCode(input_image)
```

## ì„±ëŠ¥ ì •ë³´
- ì´ í•™ìŠµ ìŠ¤í…: {self.simple_stats['total_learning_steps']}
- ë²„í¼ ì¶”ê°€ìœ¨: {self.simple_stats['buffer_additions']/(self.simple_stats['buffer_additions']+self.simple_stats['buffer_skips'])*100 if (self.simple_stats['buffer_additions']+self.simple_stats['buffer_skips']) > 0 else 0:.1f}%
- Faiss ìµœì í™”: {'ì‚¬ìš©' if FAISS_AVAILABLE else 'ë¯¸ì‚¬ìš©'}
- ì²´í¬í¬ì¸íŠ¸ ìœ„ì¹˜: Step {self.learner_step_count}, Data {self.global_dataset_index}

## ì—°ì† í•™ìŠµ ì¬ê°œ ë°©ë²•
```python
# ìƒˆë¡œìš´ ë°ì´í„°ë¡œ í•™ìŠµ ì¬ê°œ
from framework.coconut import CoconutSystem

system = CoconutSystem(config)  # ìë™ìœ¼ë¡œ ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë³µì›
system.run_experiment()  # ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ì´ì–´ì„œ í•™ìŠµ
```

Generated by CoCoNut Intelligent Replay Buffer System
Supports checkpoint resume and never loses progress!
"""
        
        readme_path = custom_save_path / f'README_coconut_{timestamp}.md'
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        print(f"[System] âœ… CoCoNut Replay Buffer ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
        print(f"  ğŸ¯ ì‚¬ìš©ì ì§€ì • ê²½ë¡œ: {custom_save_path}")
        print(f"  ğŸ“ Learner ëª¨ë¸: {custom_learner_path.name}")
        print(f"  ğŸ“ Predictor ëª¨ë¸: {custom_predictor_path.name}")
        print(f"  ğŸ“Š í†µê³„ íŒŒì¼: {custom_stats_path.name}")
        print(f"  ğŸ“– README: {readme_path.name}")
        print(f"  ğŸ• íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")
        print(f"  ğŸ“ˆ ì´ ì ì‘ ìŠ¤í…: {self.learner_step_count}")
        print(f"  ğŸ“ ë°ì´í„°ì…‹ ì™„ë£Œ: {self.global_dataset_index}")
        print(f"\n[System] ğŸ‰ COCONUT INTELLIGENT REPLAY BUFFER completed!")
        print(f"[System] ğŸ¥¥ Continual learning with intelligent diversity-based buffer!")
        print(f"[System] ğŸ’¾ Models saved to: /content/drive/MyDrive/CoCoNut_STAR")
        print(f"[System] ğŸ”„ Next run will auto-resume from checkpoints!")